[{"q":"<p>In Apache Kafka, you are working on its broker configurations. If you are required to obtain the number of requests that can be queued up for processing by the I/O threads before the network threads stop reading in new requests, then which of the following properties are used to perform this action?</p>","a":[{"id":1420990,"option":"queued.requests","correct":false},{"id":1420991,"option":"queued.message.io.requests","correct":false},{"id":1420992,"option":"queued.min.requests","correct":false},{"id":1420993,"option":"queued.max.requests","correct":true}]},{"q":"<p>In Apache Oozie, you are working on its Bundle system to define and execute a group of coordinator applications. Which of the following statements about the bundle job statuses are correct:</p>\n\n<ol>\n\t<li>When a bundle job is submitted, Oozie parses the bundle job XML. Oozie then creates a record for the bundle with the status <em>PRESUSPEND</em> and returns a unique ID.</li>\n\t<li>When the pause time reaches for a bundle job with <em>PREP</em> status, Oozie puts the job in status <em>PREPPAUSED</em>.</li>\n\t<li>When a user requests to resume a <em>PREPSUSPENDED</em> bundle job, Oozie puts the job in status <em>PREP</em>.</li>\n\t<li>When pause time is reset for a bundle job that is in a <em>PREPPAUSED</em> state, Oozie puts the job in status <em>PREP</em>.</li>\n</ol>\n\n<p>&nbsp;</p>","a":[{"id":1481709,"option":"1, 2, and 3","correct":false},{"id":1481710,"option":"2, 3, and 4","correct":true},{"id":1481711,"option":"1, 2, and 4","correct":false},{"id":1481712,"option":"1, 3, and 4","correct":false}]},{"q":"<p>In Pig, which of the following types of UDF accepts a <strong>pig</strong> value as input and returns a <strong>boolean value</strong>?</p>","a":[{"id":683173,"option":"Filter functions","correct":true},{"id":683174,"option":"Eval functions","correct":false},{"id":683175,"option":"Algebraic functions","correct":false},{"id":683176,"option":"None of these","correct":false}]},{"q":"<p>Which of the following is the workflow scheduler and the manager of Hadoop?</p>","a":[{"id":183926,"option":"HBase","correct":false},{"id":183927,"option":"Zookeeper","correct":false},{"id":183928,"option":"Oozie","correct":true},{"id":183929,"option":"Hive","correct":false}]},{"q":"<p>In Hadoop, which of the following is used to classify data?</p>","a":[{"id":170869,"option":"MapReduce, Hive, and HBase","correct":true},{"id":170870,"option":"NoSQL, MySQL, and Apps","correct":false},{"id":170871,"option":"MapReduce, Hummer, and Iguana","correct":false},{"id":170872,"option":"MapReduce, Heron, and Trumpet","correct":false}]},{"q":"<p>Consider the following tables:</p>\n\n<p>Table Name: CUSTOMERS </p>\n\n<table>\n\t<tbody>\n\t\t<tr>\n\t\t\t<td><strong>ID</strong></td>\n\t\t\t<td><strong>Name</strong></td>\n\t\t\t<td><strong>Age</strong></td>\n\t\t\t<td><strong>Address</strong></td>\n\t\t\t<td><strong>Salary</strong></td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>1</td>\n\t\t\t<td>Alice</td>\n\t\t\t<td>32</td>\n\t\t\t<td>Texas</td>\n\t\t\t<td>2000</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>2</td>\n\t\t\t<td>Bob</td>\n\t\t\t<td>25</td>\n\t\t\t<td>New York</td>\n\t\t\t<td>1500</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>3</td>\n\t\t\t<td>Ben</td>\n\t\t\t<td>23</td>\n\t\t\t<td>California</td>\n\t\t\t<td>2000</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>4</td>\n\t\t\t<td>Mike</td>\n\t\t\t<td>25</td>\n\t\t\t<td>Georgia</td>\n\t\t\t<td>6500</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>5</td>\n\t\t\t<td>Tara</td>\n\t\t\t<td>27</td>\n\t\t\t<td>Florida</td>\n\t\t\t<td>8500</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>6</td>\n\t\t\t<td>Anita</td>\n\t\t\t<td>22</td>\n\t\t\t<td>Alaska</td>\n\t\t\t<td>4500</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>7</td>\n\t\t\t<td>Lisa</td>\n\t\t\t<td>24</td>\n\t\t\t<td>Washington</td>\n\t\t\t<td>10000</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n<p>Table Name: ORDERS </p>\n\n<table>\n\t<tbody>\n\t\t<tr>\n\t\t\t<td><strong>OID</strong></td>\n\t\t\t<td><strong>Date</strong></td>\n\t\t\t<td><strong>Customer_ID</strong></td>\n\t\t\t<td><strong>Amount</strong></td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>102</td>\n\t\t\t<td>2018-10-08 00:00:00</td>\n\t\t\t<td>3</td>\n\t\t\t<td>3000</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>100</td>\n\t\t\t<td>2018-10-08 00:00:00</td>\n\t\t\t<td>3</td>\n\t\t\t<td>1500</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>101</td>\n\t\t\t<td>2018-11-20 00:00:00</td>\n\t\t\t<td>2</td>\n\t\t\t<td>1560</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>103</td>\n\t\t\t<td>2017-05-20 00:00:00</td>\n\t\t\t<td>4</td>\n\t\t\t<td>2060</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n<p>How many rows will be generated in response to the following HiveQL query?</p>\n\n<pre>hive&gt; SELECT c.ID, c.NAME, o.AMOUNT, o.DATE\nFROM CUSTOMERS c\nLEFT OUTER JOIN ORDERS o\nON (c.ID = o.CUSTOMER_ID);\n</pre>","a":[{"id":683089,"option":"4","correct":false},{"id":683090,"option":"7","correct":false},{"id":683091,"option":"8","correct":true},{"id":683092,"option":"10","correct":false}]},{"q":"<p>Which of the following enables bidirectional data transfer between Hadoop and a relational database?</p>","a":[{"id":45444,"option":"Oozie","correct":false},{"id":45445,"option":"Sqoop","correct":true},{"id":45446,"option":"FlumeNG","correct":false},{"id":45447,"option":"Zookeeper","correct":false}]}]