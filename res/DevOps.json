[{"q":"<p>Ben is tasked with a DevOps task of Continuous Integration/Continuous Deployment using Dynamic Jenkins Cluster. The task is to create a dynamic Jenkins cluster and perform deployment to the Kubernetes Cluster. The steps he has followed are -<br>\n<strong>Steps:</strong></p>\n\n<ol>\n\t<li>Container Image is created and pushed to github.</li>\n\t<li>The image is then pushed to Docker Hub after testing</li>\n\t<li>Jenkins deploys the application to the Kubernetes Cluster.</li>\n</ol>\n\n<p>Which of the following steps is missed in between by Ben to complete the aforementioned task?<br>\n<strong>Options:</strong></p>\n\n<ol>\n\t<li>\n\t<pre class=\"prettyprint\"><code>Launching the application on the Docker Hub.</code></pre>\n\t</li>\n\t<li>\n\t<pre class=\"prettyprint\"><code>Configuration of Docker Service to Docker Daemon.</code></pre>\n\t</li>\n\t<li>\n\t<pre class=\"prettyprint\"><code>Collection of the GitHub commit which pushes the image using webhooks by Jenkins.</code></pre>\n\t</li>\n\t<li>\n\t<pre class=\"prettyprint\"><code>Creation of job chain of job 1 and job 2 using build pipeline.</code></pre>\n\t</li>\n</ol>","a":[{"id":1939551,"option":"1","correct":false},{"id":1939552,"option":"2","correct":false},{"id":1939553,"option":"3","correct":true},{"id":1939554,"option":"4","correct":false}]},{"q":"<p>During a build process, you need to create targets which consist of several logical steps to be taken while performing a build. After the option message regarding the commencement of the build process, you also ensure that the code can have more than one target with dependencies between them. How do you specify the target?</p>","a":[{"id":1718707,"option":"Shipping it with a framework","correct":false},{"id":1718708,"option":"Specifying the extension of the code","correct":false},{"id":1718709,"option":"Fetching from the Turbobase","correct":false},{"id":1718710,"option":"Assigning with a name of the Build","correct":true}]},{"q":"<p>You want that the users must not be able to override the list of branches for triggers when updating the YAML file. Here are the steps that you must take:</p>\n\n<ol>\n\t<li>Select Override the YAML continuous Integration trigger from here</li>\n\t<li>Edit the pipeline in the Azure Pipelines UI</li>\n\t<li>Specify the branches to include or exclude for the trigger</li>\n\t<li>Navigate to the Triggers menu</li>\n</ol>\n\n<p>Arrange the given steps in the correct order.</p>","a":[{"id":1718867,"option":"3, 4, 1, 2","correct":false},{"id":1718868,"option":"2, 4, 1, 3","correct":true},{"id":1718869,"option":"4, 1, 3, 2","correct":false},{"id":1718870,"option":"2, 3, 4, 1","correct":false}]},{"q":"<p>You are labeling the resources in the source code files so that your team has access to identify the version of the file being included in the completed build. You are also specifying the source codes to be labeled for all the builds. How would you use the Tag Format for the user-defined and pre-defined variables for having a scope of ‘all’?</p>","a":[{"id":1718863,"option":"$(Build.DefinitionVersion)_$(Build.BuildId)_$(Build.BuildNumber)_$(My.Variable)","correct":false},{"id":1718864,"option":"refs/tags/{$(Build.BuildId)_$(Build.BuildNumber)_$(My.Variable)}","correct":false},{"id":1718865,"option":"refs/tags/{Build.DefinitionName)_$(Build.DefinitionVersion}","correct":false},{"id":1718866,"option":"$(Build.DefinitionName)_$(Build.DefinitionVersion)_$(Build.BuildId)_$(Build.BuildNumber)_$(My.Variable)","correct":true}]},{"q":"<p>You are cleaning some of the agent’s working directories that are self-hosted before running the build. You have already configured the ‘clean’ setting in the Checkout step of the pipeline. The build has performed undo of any changes in $(Build.SourcesDirectory) after clean was set to ‘true’.<br>\nWhat git commands do you need to execute before fetching the source?</p>\n\n<p><strong>Options</strong></p>\n\n<p>1.</p>\n\n<pre class=\"prettyprint\"><code>git clean -t\ngit fetchDepth = df</code></pre>\n\n<p>2.</p>\n\n<pre class=\"prettyprint\"><code>git clean -t -ffdx\ngit fetchDepth = df</code></pre>\n\n<p>3.</p>\n\n<pre class=\"prettyprint\"><code>git clean persistCredentials\nGit reset –g</code></pre>\n\n<p>4.</p>\n\n<pre class=\"prettyprint\"><code>git clean -ffdx\nGit reset --hard HEAD</code></pre>\n\n<p>&nbsp;</p>","a":[{"id":1718859,"option":"1","correct":false},{"id":1718860,"option":"2","correct":false},{"id":1718861,"option":"3","correct":false},{"id":1718862,"option":"4","correct":true}]},{"q":"<p>You want to execute different stages, steps, and jobs in a pipeline based on the trigger that you have run. What conditions will you add to your steps, jobs, and stages such that it is not included in the PR validations?</p>","a":[{"id":1718855,"option":"condition: and(succeeded(), ne(variables['Build.Reason'], 'PullRequest'))","correct":true},{"id":1718856,"option":"condition: and(succeeded(), ne(variables['exclude: true'], 'PullRequest'))","correct":false},{"id":1718857,"option":"Add ***NO_CI*** to HEAD COMMIT in the pipeline","correct":false},{"id":1718858,"option":"Set trigger to none","correct":false}]},{"q":"<p>You want to skip running a pipeline in Azure which happens every time a commit is done. What do you need to do in order to skip running CI by the Azure pipelines?</p>","a":[{"id":1718851,"option":"Configuring the Build.Reason variable","correct":false},{"id":1718852,"option":"Include [skip ci] in the commit message","correct":true},{"id":1718853,"option":"Adding a azure ig file to the pipeline","correct":false},{"id":1718854,"option":"Include [skip-checks: false] in the commit message","correct":false}]},{"q":"<p>You want to trigger the ‘VC’ branch and the wildcard ‘questions’.&nbsp;Which of the following codes would you use to trigger them in a YAML pipeline?</p>\n\n<p><strong>Code</strong></p>\n\n<p>1.</p>\n\n<pre class=\"prettyprint\"><code>trigger:\n- VC\n- questions</code></pre>\n\n<p>2.</p>\n\n<pre class=\"prettyprint\"><code>trigger:\n- VC\n- questions/*</code></pre>\n\n<p>3.</p>\n\n<pre class=\"prettyprint\"><code>trigger-yaml-branch = “VC”, wildcard = “questions”</code></pre>\n\n<p>4.</p>\n\n<pre class=\"prettyprint\"><code>trigger-yaml-branch = “VC”, wildcard = “questions/*”</code></pre>\n\n<p>&nbsp;</p>","a":[{"id":1718847,"option":"1","correct":false},{"id":1718848,"option":"2","correct":true},{"id":1718849,"option":"3","correct":false},{"id":1718850,"option":"4","correct":false}]},{"q":"<p>You are using templates for the author files in the YAML pipeline. Where can you specify triggers?</p>","a":[{"id":1718843,"option":"Template files","correct":false},{"id":1718844,"option":"The repository","correct":false},{"id":1718845,"option":"Server","correct":false},{"id":1718846,"option":"Main YAML file","correct":true}]},{"q":"<p>You are analyzing the timeline and stages of development and deployment of software to trigger a notification for every error. Into which stage will you categorize the <em>staging process</em>?</p>","a":[{"id":1718839,"option":"Source","correct":false},{"id":1718840,"option":"Build","correct":false},{"id":1718841,"option":"Test","correct":true},{"id":1718842,"option":"Deploy","correct":false}]},{"q":"<p>You want to run some automated tests in your CI/CD pipeline to find out reproducible bugs and errors in the code. However, your project has a large size and complexity, so you want to perform the tests in multiple stages to check on the integrations and entire system from the perspective of the user. What tests will you start with for the given scenario?</p>","a":[{"id":1718835,"option":"UAT Tests","correct":false},{"id":1718836,"option":"Module intensive tests","correct":false},{"id":1718837,"option":"Smoke tests","correct":true},{"id":1718838,"option":"SIT Tests","correct":false}]},{"q":"<p>You have different sets of credentials to access the 'Checkout Submodules'. Your main repository and the submodule repository are not in the same Azure DevOps organization and your repository in a different project is not accessible by your job token. You are not able to use the 'Checkout Submodules' option.<br>\nWhat script will you add to your pipeline after getting a Personal Access Token and using the base64-encode to create a basic auth token?</p>\n\n<p><strong>Options</strong></p>\n\n<p>1.</p>\n\n<pre class=\"prettyprint\"><code>git -c http.https://&lt;url of submodule repository&gt;.extraheader=\"AUTHORIZATION: Basic &lt;BASE64_ENCODED_STRING&gt;\" submodule update --init –recursive</code></pre>\n\n<p>2.</p>\n\n<pre class=\"prettyprint\"><code>git submodule add extraheader=\"AUTHORIZATION: Basic &lt;BASE64_ENCODED_STRING&gt;\"</code></pre>\n\n<p>3.</p>\n\n<pre class=\"prettyprint\"><code>git submodule add extraheader=\"AUTHORIZATION: Basic &lt;BASE64_ENCODED_STRING&gt;\" --init –recursive</code></pre>\n\n<p>4.</p>\n\n<pre class=\"prettyprint\"><code>az -c http.https://&lt;url of submodule repository&gt;.extraheader=\"AUTHORIZATION: submodule update --init --recursive</code></pre>\n\n<p>&nbsp;</p>","a":[{"id":1718831,"option":"1","correct":true},{"id":1718832,"option":"2","correct":false},{"id":1718833,"option":"3","correct":false},{"id":1718834,"option":"4","correct":false}]},{"q":"<p>While troubleshooting, you found that the pipelines for merged results were not created even with a new change pushed to the merge request. You are given some lines of code that you can use to check that ans sets the flags for GitLab instance: merge_ref_auto_sync.<br>\nLine 1: Feature.enabled?(:merge_ref_auto_sync)<br>\nLine 2: sudo gitlab-rails console<br>\nLine 3: Feature.enable(:merge_ref_auto_sync)</p>\n\n<p>Arrange the lines of code to be used in the correct order to perform the given functionality.</p>","a":[{"id":1718827,"option":"2, 3, 1","correct":false},{"id":1718828,"option":"2, 1, 3","correct":true},{"id":1718829,"option":"1, 2, 3","correct":false},{"id":1718830,"option":"1, 3, 2","correct":false}]},{"q":"<p>You want to check and enable the ‘Pipelines must succeed’ option in Gitlab CI/CD. You need to create a new pipeline for the merged results if an error occurs with the following message “The pipeline for this merge request failed.”&nbsp; What series of navigations and steps will you take to enable the given functionality?</p>","a":[{"id":1718823,"option":"Settings > General > Merge requests","correct":false},{"id":1718824,"option":"File > Merge Requests > Merge train","correct":false},{"id":1718825,"option":"Go to Pipelines > Run pipeline > Start/Add to merge train when pipeline succeeds","correct":true},{"id":1718826,"option":"Settings > General > Merge train","correct":false}]},{"q":"<p>You are using pipelines for merge requests using the only/except keywords by a branch ref: refs/heads/my-feature-branch but the pipelines for merge requests require special treatment when using only/except. So, some of the configurations don’t work as expected. Which of the following code combinations will work as expected?</p>\n\n<p><strong>Code</strong></p>\n\n<p>1.</p>\n\n<pre class=\"prettyprint\"><code>test:\nonly: [merge_requests]\nExcept: [/^docs-/]</code></pre>\n\n<p>2.</p>\n\n<pre class=\"prettyprint\"><code>test:\nonly: [merge_requests]\nExcept: [/REF_NAME^docs-/]</code></pre>\n\n<p>3.</p>\n\n<pre class=\"prettyprint\"><code>test:\nonly: [merge_requests]\nexcept:\nVariables:\n- $CI_COMMIT =~ /^docs-/</code></pre>\n\n<p>4.</p>\n\n<pre class=\"prettyprint\"><code>test:\nonly: [merge_requests]\nexcept:\nVariables:\n- $CI_COMMIT_REF_NAME =~ /^docs-/</code></pre>\n\n<p>&nbsp;</p>","a":[{"id":1718819,"option":"1","correct":false},{"id":1718820,"option":"2","correct":false},{"id":1718821,"option":"3","correct":false},{"id":1718822,"option":"4","correct":true}]},{"q":"<p>You want to prevent a specific runner from being enabled for other projects in&nbsp;GitLab CI/CD. You are configuring it as “locked”. When can you get the option for configuring these settings?</p>","a":[{"id":1718815,"option":"Checking the maximum timeout for the runner during the execution","correct":false},{"id":1718816,"option":"Accessing the  protected branches options by clicking on Runners in Settings","correct":false},{"id":1718817,"option":"Registering the runner the first time","correct":true},{"id":1718818,"option":"Enabling the pipeline for merge request","correct":false}]},{"q":"<p>You want the GitLab to identify the origin of the job taken and tie the pipelines internally together such that the relationships on pipeline graphs can be viewed. What would you use to trigger the pipelines enabling the given functionalities?</p>","a":[{"id":1718811,"option":"CI_JOB_TOKEN","correct":true},{"id":1718812,"option":"CI_PIPELINE_SOURCE","correct":false},{"id":1718813,"option":"rules keyword","correct":false},{"id":1718814,"option":".gitlab-ci.yml file","correct":false}]},{"q":"<p>You have a mirrored repository where the GitLab pulls from.&nbsp;What series of navigations will you make to enable the triggering of the pipeline?</p>","a":[{"id":1718807,"option":"Pipeline settings > Schedules > Build > Mirror Updates > Trigger pipelines","correct":false},{"id":1718808,"option":"Settings > Repository > Pull from a remote repository > Trigger pipelines for mirror updates.","correct":true},{"id":1718809,"option":"File > GitLab > Repository > Trigger > Checklist","correct":false},{"id":1718810,"option":"Pipeline settings > Schedules > Build > Trigger pipelines","correct":false}]},{"q":"<p>You want to reduce Docker image size and is using apt. What would you add to avoid unnecessary packages?</p>","a":[{"id":1718803,"option":"Debian-ignore","correct":false},{"id":1718804,"option":"yum clean all","correct":false},{"id":1718805,"option":"--no-install-recommends","correct":true},{"id":1718806,"option":"rm -rf","correct":false}]},{"q":"<p>You want to fetch metrics from the API and pipeline events along with checking branches and get the pipeline status and duration. You then need to export these metrics about the jobs and environment.&nbsp;Which tool would you use to perform the given operations?</p>","a":[{"id":1718799,"option":"GitLab Runner","correct":false},{"id":1718800,"option":"Prometheus Node Exporter","correct":false},{"id":1718801,"option":"GitLab CI Pipelines Exporter","correct":true},{"id":1718802,"option":"Docker","correct":false}]},{"q":"<p>You want to configure the minimum and maximum pipeline duration of the pipeline for GitLab. What would you check among the given options?</p>","a":[{"id":1718795,"option":"Container Image size","correct":false},{"id":1718796,"option":"Critical Path","correct":true},{"id":1718797,"option":"Flaky unit test","correct":false},{"id":1718798,"option":"DAG","correct":false}]},{"q":"<p>You want to optimize your pipeline. You have decided to cache the dependencies of Node Js Modules. Which of the following codes would you use to cache Node.js dependencies?</p>\n\n<p><strong>Code Snippets</strong></p>\n\n<p>1.</p>\n\n<pre class=\"prettyprint\"><code>image: node:latest\ncache: key: ${CI_COMMIT_REF_SLUG}\nPaths:\n- .npm/\nbefore_script:\n- npm ci --cache .npm –prefer-offline\ntest_async:\nscript:\n- - curl --show-error --silent \"https://getcomposer.org/installer\" |</code></pre>\n\n<p>2.</p>\n\n<pre class=\"prettyprint\"><code>image: node:v^7.1.2\nCache:\nkey: ${CI_COMMIT_REF_SLUG}\npaths: - vendor/\nbefore_script:\n- npm ci --cache .npm –prefer-offline\ncomposer.phar install\nTest:\nScript:\n- vendor/bin/nodeunit –configuration</code></pre>\n\n<p>3.</p>\n\n<pre class=\"prettyprint\"><code>image: node:latest\ncache: key: ${CI_COMMIT_REF_SLUG}\nPaths:\n- .npm/\nbefore_script:\n- npm ci --cache .npm –prefer-offline\ntest_async:\nscript:\n- node ./specs/start.js ./specs/async.spec.js</code></pre>\n\n<p>4.</p>\n\n<pre class=\"prettyprint\"><code>image: node:v^7.1.2\nCache:\nkey: ${CI_COMMIT_REF_SLUG}\npaths: - vendor/\nbefore_script:\n- curl --show-error --silent \"https://getcomposer.org/installer\"\ncomposer.phar install\nTest:\nScript:\n- vendor/bin/nodeunit –configuration</code></pre>\n\n<p>&nbsp;</p>","a":[{"id":1718791,"option":"1","correct":false},{"id":1718792,"option":"2","correct":false},{"id":1718793,"option":"3","correct":true},{"id":1718794,"option":"4","correct":false}]},{"q":"<p>You have found out that the pipeline has been working very inefficiently and you need to check and configure it to ensure that it functions according to the requirements and in a very efficient manner. Here are some of the indicators that might be useful to check the efficiency of the pipeline:<br>\n1. Total number of stages and jobs<br>\n2. Dependency relationships between the jobs<br>\n3. The “critical path”<br>\n4. Pipeline trigger cycles<br>\n<br>\nWhich of the options you must look into on a priority basis?</p>","a":[{"id":1718787,"option":"1, 2, 3","correct":true},{"id":1718788,"option":"1, 2, 4","correct":false},{"id":1718789,"option":"2, 3, 4","correct":false},{"id":1718790,"option":"1, 3, 4","correct":false}]},{"q":"<p>You want to check the evolution of the project code coverage along the time in the form of a graph and download the data in a CSV file of your project. What series of navigations will help you in achieving that?</p>","a":[{"id":1718779,"option":"Navigate to Settings > CI/CD > General pipelines > Download CSV data","correct":false},{"id":1718780,"option":"Navigate to Tools > Data > Download and then convert it to CSV format","correct":false},{"id":1718781,"option":"Navigate to Project Analytics > Repository and click on Download raw data( .csv).","correct":true},{"id":1718782,"option":"Navigate to Tools > Analytics > Export > CSV format file","correct":false}]},{"q":"<p>You are triggering a child pipeline using a local YAML file. You want the parent pipelines to trigger the child pipelines without waiting. Which of the following codes would you use to compose the child pipeline?</p>\n\n<p><strong>Code Snippets</strong></p>\n\n<p>1.</p>\n\n<pre class=\"prettyprint\"><code>microservice_a:\nTrigger:\nInclude:\n- project: 'my-group/my-pipeline-library'\nfile: 'path/to/ci-config.yml'</code></pre>\n\n<p>2.</p>\n\n<pre class=\"prettyprint\"><code>microservice_a:\nTrigger:\nInclude:\n- local: path/to/microservice_a.yml\nTemplate: Security/SAST.gitlab-ci.yml</code></pre>\n\n<p>3.</p>\n\n<pre class=\"prettyprint\"><code>microservice_a:\nTrigger:\nInclude: path/to/microservice_a.yml</code></pre>\n\n<p>4.</p>\n\n<pre class=\"prettyprint\"><code>microservice_a:\nTrigger:\nInclude:\n- local: path/to/microservice_a.yml\n- template: Security/SAST.gitlab-ci.yml</code></pre>","a":[{"id":1718775,"option":"1","correct":false},{"id":1718776,"option":"2","correct":false},{"id":1718777,"option":"3","correct":false},{"id":1718778,"option":"4","correct":true}]},{"q":"<p>You are hosting <em>CI configuration </em>in a different project in Gitlab. What do you need to ensure so that it is hosted successfully?</p>","a":[{"id":1718771,"option":"Changing the host configuration to Group Settings","correct":false},{"id":1718772,"option":"Including the group and project name at the end of the path","correct":true},{"id":1718773,"option":"Ending the URL with .yml","correct":false},{"id":1718774,"option":"Changing the value of Test coverage parsing field","correct":false}]},{"q":"<p>You want to change the number of maximum changes for the Gitlab that CI/CD fetches while cloning a repository. You are changing the value of git depth.&nbsp;What is the maximum value that you can assign to the git depth?</p>","a":[{"id":1718767,"option":"1","correct":false},{"id":1718768,"option":"10","correct":false},{"id":1718769,"option":"100","correct":false},{"id":1718770,"option":"1000","correct":true}]},{"q":"<p>You want the artifact path that is parsed by Gitlab to match the syntax for the system’s operating system running Gitlab. What separator would you use when testing the job using a Windows Runner?</p>","a":[{"id":1718763,"option":"_","correct":false},{"id":1718764,"option":"/","correct":false},{"id":1718765,"option":"\\","correct":true},{"id":1718766,"option":"!","correct":false}]},{"q":"<p>You want to make tasks easier by not requiring the Gitlab Runner to trigger the pipelines that are cross-project. You have used the code given below in order to do so.&nbsp;What are you trying to achieve with the following code?</p>\n\n<pre class=\"prettyprint\"><code>rspec:\nstage: test\nscript: bundle exec rspec\n\nstaging:\nvariables:\nENVIRONMENT: staging\nstage: deploy\ntrigger: my/deployment\n</code></pre>\n\n<p>&nbsp;</p>","a":[{"id":1718759,"option":"Changing the status of the job","correct":false},{"id":1718760,"option":"Specifying a downstream pipeline branch","correct":false},{"id":1718761,"option":"Passing CI/CD variables to a downstream pipeline With the variables keyword","correct":false},{"id":1718762,"option":"Triggering a downstream pipeline using a bridge job","correct":true}]},{"q":"<p>You have defined the regular expression for each coverage report in Gitlab such that the job is matched and it will have the test coverages value defined in the pipeline. Now, you want the coverage report only for a particular job. What markdown code link would you use to access that?</p>\n\n<p><strong>Options</strong></p>\n\n<ol>\n\t<li>\n\t<pre class=\"prettyprint\"><code>https://gitlab.example.com/&lt;namespace&gt;/&lt;project&gt;/badges/&lt;branch&gt;/coverage.svg</code></pre>\n\t</li>\n\t<li>\n\t<pre class=\"prettyprint\"><code>https://gitlab.example.com/&lt;namespace&gt;/&lt;project&gt;/badges/&lt;branch&gt;/coverage.svg?style=flat</code></pre>\n\t</li>\n\t<li>\n\t<pre class=\"prettyprint\"><code>![coverage](https://gitlab.com/gitlab-org/gitlab/badges/master/coverage.svg?job=coverage)</code></pre>\n\t</li>\n\t<li>\n\t<pre class=\"prettyprint\"><code>![coverage]https://gitlab.com/gitlab-org/gitlab/badges/master/coverage.svg?job=karma&amp;key_text=Frontend+Coverage&amp;key_width=130</code></pre>\n\t</li>\n</ol>\n\n<p>&nbsp;</p>","a":[{"id":1718755,"option":"1","correct":false},{"id":1718756,"option":"2","correct":false},{"id":1718757,"option":"3","correct":true},{"id":1718758,"option":"4","correct":false}]},{"q":"<p>If a new development job has been executed while configuring your pipeline, the old one can fail. The modal will show you a warning that the environment source code could be overwritten with the older source code.&nbsp;What action will trigger such a warning?</p>","a":[{"id":1718751,"option":"Updating the pipeline badge","correct":false},{"id":1718752,"option":"Crating a new job","correct":false},{"id":1718753,"option":"Retrying the failed job","correct":true},{"id":1718754,"option":"Accessing the status badge","correct":false}]},{"q":"<p>You want to set the maximum number of updations in the CI/CD fetches so that the cloning process becomes faster in order to make the pipeline execution faster. What would you use to perform the given scenario?</p>","a":[{"id":1718747,"option":"max_changes","correct":false},{"id":1718748,"option":"git depth","correct":true},{"id":1718749,"option":"git limit","correct":false},{"id":1718750,"option":"max_updations","correct":false}]},{"q":"<p>You want to manually run a pipeline. The variables are either predefined or specified manually as the code build is required out of the scope of the pipeline’s operation. What series of navigations and operations would you take in a Gitlab environment to run a pipeline?</p>","a":[{"id":1718743,"option":"CI/CD > Pipelines > Run pipeline > Select the branch and enter environment variables","correct":true},{"id":1718744,"option":"CI/CD > Configure Pipeline > Branch > Environment variables > Run Pipeline","correct":false},{"id":1718745,"option":"File  > Pipelines > Configure > Run","correct":false},{"id":1718746,"option":"File  > Pipelines > Configure > Select the branch and enter environment variables > Run Pipeline","correct":false}]},{"q":"<p>You want to track the personal pipeline’s usage for shared runners for the personal projects which are in the same group such that if the pipeline is triggered, the project’s owner namespace’s pipeline quota will be used.&nbsp;What is used to track the usage for each such group?</p>","a":[{"id":1718739,"option":"Pipeline quota","correct":false},{"id":1718740,"option":"Group project level","correct":false},{"id":1718741,"option":"group quota","correct":false},{"id":1718742,"option":"usage quota","correct":true}]},{"q":"<p>You are picking a pipeline job using a runner. The meta data for the job is provided by Gitlab and the \"refspec\" for the pipeline is <em>“+refs/heads/:refs/remotes/origin/\"</em>&nbsp;in your project repository. What pipeline type are you using for the above job?</p>","a":[{"id":1718735,"option":"Pipeline for Tags","correct":false},{"id":1718736,"option":"Pipeline for Branches","correct":true},{"id":1718737,"option":"Pipeline for navigations","correct":false},{"id":1718738,"option":"Pipeline for merge requests","correct":false}]},{"q":"<p>You are using Docker as a virtual environment to create a server. You want to develop a <em>CI/CD pipeline</em> using Docker and Jenkins. So, you started Jenkins and Docker from your terminal and created a new job in Jenkins for the required port and chose the freestyle project.&nbsp;Some of the steps that need to be followed to perform the above scenario are mentioned below. Arrange these steps in the correct order.</p>\n\n<ol>\n\t<li>&nbsp;Create a new job start the integration and build of Docker Container</li>\n\t<li>&nbsp;Choose Source Code Management and click on Apply followed by saving it after providing the Git repository</li>\n\t<li>&nbsp;Post Build Actions and configure them followed choosing the Build Pipeline View and clicking on run</li>\n\t<li>&nbsp;Run the Shell from the Build option and write all the shell commands</li>\n</ol>","a":[{"id":1718731,"option":"4, 2, 1, 3","correct":true},{"id":1718732,"option":"2, 3, 1, 4","correct":false},{"id":1718733,"option":"4, 1, 3, 2","correct":false},{"id":1718734,"option":"2, 3, 4, 1","correct":false}]},{"q":"<p>You are defining prefilled variables using the keywords value and description while running a manual pipeline. If you manually trigger the pipeline, it will show all the variables with description and value, which can be modified and are overridden.&nbsp;Where are the variables defined?</p>","a":[{"id":1718727,"option":"In the file_bar pre-populate file","correct":false},{"id":1718728,"option":"In the .gitlab-ci.yml file","correct":true},{"id":1718729,"option":"In the Administrator file","correct":false},{"id":1718730,"option":"In the refs.pipeline.yml file","correct":false}]},{"q":"<p>You want your pipelines to be very efficient and running at the lowest possible time. You also want to ensure the coverage of when the job needs to fan in or out, and/or merge back together (diamond dependencies) which happens when the operating system handles multi-platform builds and multiple web of dependencies. The relationships must not block each other if not required and confirm that the developers get outputs without caring about the stages of the pipeline. What would you do to ensure the above functionality?</p>","a":[{"id":1718723,"option":"Use Multi-project Pipeline","correct":false},{"id":1718724,"option":"Use Direct Acyclic Graph","correct":true},{"id":1718725,"option":"Use Parent-Child pipeline","correct":false},{"id":1718726,"option":"Merge the trains","correct":false}]},{"q":"<p>You were configuring the pipeline with jobs in the <em>.gitlab-ci.yml</em> file. However, it failed. Here are some of the places that can be checked.</p>\n\n<ol>\n\t<li>In pipeline collections having grouped jobs</li>\n\t<li>In the pipeline graph, on the pipeline detail view</li>\n\t<li>In the job views, in the global and detailed views of a job</li>\n\t<li>In the pipeline widgets, in the merge requests and commit pages</li>\n</ol>\n\n<p>Which three places would be most suitable for finding reasons for the failure in the pipeline?</p>","a":[{"id":1718719,"option":"1, 3, 4","correct":false},{"id":1718720,"option":"2, 3, 4","correct":true},{"id":1718721,"option":"1, 2, 4","correct":false},{"id":1718722,"option":"1, 2, 3","correct":false}]},{"q":"<p>You need to ensure that the baseline code is successfully tested with the source code repository management server. You are using Git for continuous integration. How would you perform the given operations?</p>","a":[{"id":1718715,"option":"git add . > git init > git push","correct":false},{"id":1718716,"option":"git commit > git init > git push","correct":false},{"id":1718717,"option":"git init > git add > git commit","correct":true},{"id":1718718,"option":"git add . > git commit > git push","correct":false}]},{"q":"<p>An event was triggered during a build fail and all the stakeholders to the project were notified of the build fail. How would you set up the email notification using the TeamCity for Continuous Integration Process to align the team effort?</p>","a":[{"id":1718711,"option":"Project Dashboard > Email Notifier > SMTP Server > New Credentials in Users option","correct":true},{"id":1718712,"option":"Users > Email Notifier > Select roles","correct":false},{"id":1718713,"option":"Users > Email Notifier > Select roles > Project Dashboard > SMTP Server","correct":false},{"id":1718714,"option":"Users > Email Notifier > Select roles > SMTP Server","correct":false}]},{"q":"<p>While using MSBuild to carry out the tasks, you want to find out the port number, the path of a web server, and the authentication while running the application. Which of the following would you configure to determine the information required?</p>","a":[{"id":1718703,"option":"ItemGroup","correct":false},{"id":1718704,"option":"IIS Settings","correct":true},{"id":1718705,"option":"Build tool","correct":false},{"id":1718706,"option":"Installation component","correct":false}]},{"q":"<p>You have linked the<strong> </strong><em>Continuous Integration Server</em> and coded your base code in Git. Now, you decided to define the tasks in the continuous server for triggers. Arrange the steps in the correct order for defining the tasks:</p>\n\n<ol>\n\t<li>Click on Add new trigger in the project dashboard and then choose a trigger, for example, VCS trigger.</li>\n\t<li>Give the following commands: git add &gt; git commit.</li>\n\t<li>Click on Show Advanced Options and select the required options and save them.</li>\n\t<li>Open the page in an IDE preferably VS Code and then enter the command git status.</li>\n</ol>","a":[{"id":1718699,"option":"4, 1, 3, 2","correct":true},{"id":1718700,"option":"1, 4, 2, 3","correct":false},{"id":1718701,"option":"3, 4, 2, 1","correct":false},{"id":1718702,"option":"4, 2, 3, 1","correct":false}]},{"q":"<p>You are keeping a check on the code built by the <em>CI</em> server by ensuring that every test case is in the correct place to be integrated whenever required. So, you need to define a test case in .NET for the TeamCity servers to run the test and identify the bugs in our code.<br>\nYou wrote the following code in a <em>.cs file</em>:</p>\n\n<pre class=\"prettyprint\"><code>using System;\nusing System.Linq;\nusing System.Web;\nusing System.Collections.Generic;\nusing System.Web.UI;\nusing System.Web.UI.WebControls;\nnamespace Test {\npublic partial class TestClass : System.Web.UI.Page {\nQuestion ci = new Question();\nprotected void Page_Load(object sender, EventArgs e) {\nci.Name = \"Continuous Integration\";\n}\n}\n}</code></pre>\n\n<p>What are we doing in the given code?</p>","a":[{"id":1718695,"option":"Adding a new unit test case in the project","correct":false},{"id":1718696,"option":"Referencing the ci.Name variable","correct":false},{"id":1718697,"option":"Creating a constructor for continuous integration","correct":false},{"id":1718698,"option":"Creating a new instance","correct":true}]},{"q":"<p>You want to check if the database server has been placed correctly in Amazon before finally deploying it in the <em>Continuous Integration</em> phase for the server.<br>\nArrange the following steps in the correct order to perform the check:</p>\n\n<ol>\n\t<li>&nbsp;Go to Launch DB Instance and then click on the DB Instance link.</li>\n\t<li>&nbsp;Select the SQL server Lab to be used after clicking on Launch DB.</li>\n\t<li>&nbsp;Browse the Amazon Console and create your database in the section followed by clicking on instances.</li>\n\t<li>&nbsp;Check on the details like DB Engine, License Model, DB Engine Version, Storage type, and other settings, and then click on Next.</li>\n</ol>","a":[{"id":1718691,"option":"1, 4, 2, 3","correct":false},{"id":1718692,"option":"2, 4, 1, 3","correct":false},{"id":1718693,"option":"3, 4, 2, 1","correct":true},{"id":1718694,"option":"3, 2, 4, 1","correct":false}]},{"q":"<p>Before running the actual tests with CI/CD pipelines,&nbsp;an&nbsp;automated code review of inspection is conducted on code. The review includes checking the code's language standards, architectural layering adherence, code duplication, and many others aspects. In which of the following steps is this review performed?</p>","a":[{"id":1660959,"option":"Continuous integration","correct":false},{"id":1660960,"option":"Continuous testing","correct":false},{"id":1660961,"option":"Continuous delivery","correct":false},{"id":1660962,"option":"Continuous inspection","correct":true}]},{"q":"<p>In which of the following stages of CI/CD pipelines a change in code triggers a notification to a CI/CD tool that runs the corresponding pipeline?</p>","a":[{"id":1655425,"option":"Build ","correct":false},{"id":1655426,"option":"Test ","correct":false},{"id":1655427,"option":"Source ","correct":true},{"id":1655428,"option":"Deploy ","correct":false}]},{"q":"<p>Which of the following steps of CI/CD pipelines mainly focuses&nbsp;on:</p>\n\n<ul>\n\t<li>Instant responses to bugs</li>\n\t<li>Reliable and stable releases</li>\n</ul>","a":[{"id":1658835,"option":"Continuous integration","correct":false},{"id":1658836,"option":"Continuous delivery","correct":true},{"id":1658837,"option":"Continuous deployment","correct":false},{"id":1658838,"option":"All of these","correct":false}]},{"q":"<p>An organization&nbsp;wants to increase its competitive efficiency. The management team decides to release features on a daily or hourly basis. They also want to ensure cross-department coordination. Which of the following steps of CI/CD pipelines will the organization adapt in this scenario?</p>","a":[{"id":1659002,"option":"Continuous integration","correct":false},{"id":1659003,"option":"Continuous delivery ","correct":false},{"id":1659004,"option":"Continuous deployment","correct":true},{"id":1659005,"option":"Continuous development","correct":false}]},{"q":"<p>An organization is adopting the <em>continuous integration</em> method of CI/CD pipelines to improve its software development process. Which of the following are the most significant requirements for continuous integration:</p>\n\n<ol>\n\t<li>Always run all commit tests on your localhost before committing.</li>\n\t<li>Check-in on a broken build.</li>\n\t<li>Keep the build and test process sufficiently long.</li>\n\t<li>Create a comprehensive automated test suite.</li>\n</ol>","a":[{"id":1659177,"option":"1, 2, and 4","correct":false},{"id":1659178,"option":"2 and 3","correct":false},{"id":1659179,"option":"1 and 4","correct":true},{"id":1659180,"option":"1, 2, and 3","correct":false}]},{"q":"<p>An organization is using CI/CD pipelines to improve its software development process. One of the key aspects of continuous integration is to see how the builds perform, gather important metrics, document those outcomes, and generate continuous feedback through continuous builds.&nbsp;</p>\n\n<p>What are the<strong> </strong>benefits of having these metrics in place?</p>\n\n<ol>\n\t<li>The metrics investigate and improve any infrastructure resources to reduce the build duration.</li>\n\t<li>They evaluate and improve the performance of these tests that can dramatically reduce the build duration.</li>\n\t<li>If developers are not committing code to a version control repository frequently, then these metrics perform a high-level analysis of the integration build environment to determine the bottlenecks.</li>\n</ol>","a":[{"id":1659181,"option":"1 and 2","correct":false},{"id":1659182,"option":"2 and 3","correct":false},{"id":1659183,"option":"1 and 3","correct":false},{"id":1659184,"option":"All of these","correct":true}]},{"q":"<p>A company is using CI/CD pipelines with DevOps to increase the efficiency of its&nbsp;software development process. Which of the following tests are conducted in the continuous integration phase of this pipeline:</p>\n\n<ol>\n\t<li>Unit&nbsp;</li>\n\t<li>Component&nbsp;</li>\n\t<li>Performance&nbsp;</li>\n\t<li>Acceptance&nbsp;</li>\n\t<li>Black box</li>\n</ol>","a":[{"id":1660923,"option":"1 , 2, 3, and 4","correct":false},{"id":1660924,"option":"1, 2, and 4","correct":false},{"id":1660925,"option":"1, 3, 4, and 5","correct":false},{"id":1660926,"option":"All of these","correct":true}]},{"q":"<p>In the Software Development Life Cycle (SDLC), testing is a phase where developers check whether the software satisfies the specific requirements and expectations of the customer by testing for bugs and errors. Testing tools help testers to find issues in their products before the users do ultimately resulting in better quality software. You are using CI/CD pipelines in your software development process.&nbsp;</p>\n\n<p>Which of the following is not<strong> </strong>a CI/CD tool that is used in testing?</p>","a":[{"id":1660943,"option":"Wercker","correct":false},{"id":1660944,"option":"Terraform","correct":false},{"id":1660945,"option":"Google Chrome Developer","correct":true},{"id":1660946,"option":"Go continuous delivery","correct":false}]},{"q":"<p>An organization wants to improve its competitive edge by moving away from traditional waterfall methods. This process is getting executed so that&nbsp;engineers and developers no longer face delays because of repetitive activities that are highly dependent on the completion of other tasks. Which of the following will be the best method to&nbsp;increase the organization’s ability to deliver applications and services faster?</p>","a":[{"id":1655441,"option":"Agile","correct":false},{"id":1655442,"option":"Continuous integration in agile","correct":false},{"id":1655443,"option":"DevOps and the CI/CD pipeline","correct":true},{"id":1655444,"option":"DevOps","correct":false}]},{"q":"<p>Suppose you want to deploy your application on <em>Kubernetes</em> using minikube. Some of the initial steps to create a Kubernetes&nbsp;cluster are mentioned below. Which steps should you run and in what order to set up a cluster in minikube?</p>\n\n<ol>\n\t<li>kubernetes version</li>\n\t<li>minikube version</li>\n\t<li>minikube start</li>\n\t<li>kubectl version</li>\n\t<li>kubectl start</li>\n\t<li>kubectl cluster-info</li>\n\t<li>kubectl get nodes</li>\n</ol>","a":[{"id":1691734,"option":"1, 3, 5, 6, 7","correct":false},{"id":1691735,"option":"1, 4, 5, 6, 7","correct":false},{"id":1691736,"option":"2. 3, 4, 6, 7","correct":true},{"id":1691737,"option":"2. 4, 5, 6, 7","correct":false}]},{"q":"<p>Suppose you want to deploy your application on <em>Kubernetes</em> using minikube. The pod can be&nbsp;accessed by its internal IP address within the Kubernetes Cluster. How can you make the&nbsp;<em>\"my-node\"</em>&nbsp;container accessible from outside the Kubernetes virtual network?</p>","a":[{"id":1691730,"option":"kubectl get deploy my-node --type=LoadBalancer --port=8080","correct":false},{"id":1691731,"option":"kubectl get deployment my-node --type=LoadBalancer --port=8080","correct":false},{"id":1691732,"option":"kubectl expose deploy my-node --type=LoadBalancer --port=8080","correct":false},{"id":1691733,"option":"kubectl expose deployment my-node --type=LoadBalancer --port=8080","correct":true}]},{"q":"<p>You are working on Kubernetes using <em>minikube</em>. Which of the following code snippet is the correct way to interact with your Kubernetes cluster&nbsp;and deploy an application to minikube?</p>\n\n<p><strong>Code</strong></p>\n\n<p>1.</p>\n\n<pre class=\"prettyprint\"><code>kubectl create deploy -minikube1 -image=k8s.gcr.io/echoserver:1.4\nkubectl expose deploy -minikube1 -type=LoadBalancer -port=8080</code></pre>\n\n<p>2.</p>\n\n<pre class=\"prettyprint\"><code>kubectl create deployment -minikube1 -image=k8s.gcr.io/echoserver:1.4\nkubectl expose deployment -minikube1 -type=LoadBalancer -port=8080</code></pre>\n\n<p>3.</p>\n\n<pre class=\"prettyprint\"><code>kubectl create deploy hello-minikube1 -image=k8s.gcr.io/echoserver:1.4\nkubectl expose deploy hello-minikube1 -type=LoadBalancer --port=8080</code></pre>\n\n<p>4.</p>\n\n<pre class=\"prettyprint\"><code>kubectl create deployment hello-minikube1 --image=k8s.gcr.io/echoserver:1.4\nkubectl expose deployment hello-minikube1 --type=LoadBalancer --port=8080</code></pre>\n\n<p>&nbsp;</p>","a":[{"id":1691551,"option":"1","correct":false},{"id":1691552,"option":"2","correct":false},{"id":1691553,"option":"3","correct":false},{"id":1691554,"option":"4","correct":true}]},{"q":"<p>You want to use <em>Kubernetes</em> on your personal computer. Which of the following tools can you use to run Kubernetes locally?</p>","a":[{"id":1691176,"option":"kind","correct":false},{"id":1691177,"option":"kube","correct":false},{"id":1691178,"option":"minikube","correct":true},{"id":1691179,"option":"kubeadm","correct":false}]},{"q":"<p>Your organization is&nbsp;using <em>Kubernetes </em>to manage and scale cloud-based work. Here, Statefulsets manages the deployment and scaling of a set of Pods. StatefulSet is the workload API object used to manage stateful applications.</p>\n\n<p>Which of the following statements are true with respect to StatefulSets in Kubernetes?</p>\n\n<p><strong>Statements</strong></p>\n\n<ol>\n\t<li>StatefulSets provides a guarantee&nbsp;on the termination of pods when a StatefulSet is deleted</li>\n\t<li>Deleting or scaling a StatefulSet down will&nbsp;delete the volumes associated with the StatefulSet</li>\n\t<li>StatefulSet manages Pods that are based on an identical container spec</li>\n\t<li>StatefulSet maintains a sticky identity for each of their Pods</li>\n</ol>","a":[{"id":1690370,"option":"1 and 2","correct":false},{"id":1690371,"option":"3 and 4","correct":true},{"id":1690372,"option":"2, 3 and 4","correct":false},{"id":1690373,"option":"1 , 2 and 4","correct":false}]},{"q":"<p>Your organization is using <em>Kubernetes</em> to manage its cloud activities. If you&nbsp;update a Deployment while an existing rollout is in progress then which of the following events&nbsp;will occur?</p>\n\n<p><strong>Events</strong></p>\n\n<ol>\n\t<li>The Deployment will create a new ReplicaSet as per the update</li>\n\t<li>The Deployment will scale down&nbsp;the new ReplicaSet</li>\n\t<li>The Deployment will scale up the new ReplicaSet</li>\n\t<li>The Deployment will roll&nbsp;over the&nbsp;previously scaling&nbsp;ReplicaSet</li>\n\t<li>The Deployment will scale up the old ReplicaSet</li>\n</ol>","a":[{"id":1690266,"option":"1 , 2 and 4","correct":false},{"id":1690267,"option":"3, 4 and 5","correct":false},{"id":1690268,"option":"2, 4 and 5","correct":false},{"id":1690269,"option":"1, 3 and 5","correct":true}]},{"q":"<p>Suppose your organization is using <em>Kubernetes</em> to manage cloud-based activities. You are having nodes in <em>2</em> different zones. In which order does the scheduler evaluate the feasibility of the nodes,&nbsp;if you have the&nbsp;nodes in the following&nbsp;zones?</p>\n\n<p><em><strong>Note:</strong> Kubernetes version - v1.14</em></p>\n\n<pre class=\"prettyprint\"><code>Zone 1: Node 1, Node 3, Node 4, Node 5\nZone 2: Node 2, Node 6</code></pre>","a":[{"id":1689691,"option":"Node 1, Node 3, Node 4, Node 5, Node 2, Node 6","correct":false},{"id":1689692,"option":"Node 1, Node 3, Node 2, Node 6, Node 4, Node 5","correct":false},{"id":1689693,"option":"Node 1, Node 2, Node 3, Node 6, Node 4, Node 5","correct":true},{"id":1689694,"option":"Node 2, Node 1, Node 6, Node 3, Node 4, Node 5","correct":false}]},{"q":"<p>You are working in an organization that is using <em>Kubernetes</em> to manage its cloud-based activities. Which of the following commands can you use to create a new service object to load balance traffic across Pods?</p>","a":[{"id":1689490,"option":"create","correct":false},{"id":1689491,"option":"run","correct":false},{"id":1689492,"option":"autoscale","correct":false},{"id":1689493,"option":"expose","correct":true}]},{"q":"<p>Alice is working in an organization that is using <em>Kubernetes</em> to manage its cloud activities. Which&nbsp;of the following situation applies&nbsp;if you do not specify a memory limit for a container?</p>","a":[{"id":1674446,"option":"The Container could use all of the memory available on the Node","correct":false},{"id":1674447,"option":"Cluster administrators can use a LimitRange to specify a default value for the memory limit","correct":false},{"id":1674448,"option":"A Container with no resource limits will have a lesser chance of being killed","correct":false},{"id":1674449,"option":"Both A and B","correct":true}]},{"q":"<p>Your organization is using Kubernetes to handle cloud activities. There are many&nbsp;teams working on different projects and they need to share a Kubernetes cluster. So using <em>namespaces</em>&nbsp;clusters can be organized into virtual sub-clusters which can be used by different teams for their respective projects. What are some of the functionalities of namespaces apart from this which make it useful for us?</p>\n\n<p><strong>Options</strong></p>\n\n<ol>\n\t<li>Namespaces help pod-to-pod communication using the same namespace</li>\n\t<li>Names of resources need to be unique within a namespace and also&nbsp;across namespaces</li>\n\t<li>Namespaces provide logical separation between the teams and their environments</li>\n\t<li>Namespaces are virtual clusters that can sit on top of the same physical cluster</li>\n</ol>","a":[{"id":1674442,"option":"1, 2, and 3","correct":false},{"id":1674443,"option":"2, 3, and 4","correct":false},{"id":1674444,"option":"1, 2, and 4","correct":false},{"id":1674445,"option":"1, 3, and 4","correct":true}]},{"q":"<p>Your organization wants to enhance its storage capacity and is using&nbsp;<em>Kubernetes</em> to manage its cloud infrastructure. Kubernetes keeps track of storage capacity and the scheduler uses that information to schedule Pods. In which of the following cases, storage capacity information is used by the Kubernetes scheduler?</p>\n\n<p><strong>Options</strong></p>\n\n<p>1. If the&nbsp;<code>CSIStorageCapacity</code>&nbsp;feature gate is false</p>\n\n<p>2. If a Pod uses a volume that has not been created yet</p>\n\n<p>3. If&nbsp;the&nbsp;<code>CSIDriver</code>&nbsp;object for the driver has&nbsp;<code>StorageCapacity</code>&nbsp;set to true</p>","a":[{"id":1670501,"option":"1 and 2","correct":false},{"id":1670502,"option":"1 and 3","correct":false},{"id":1670503,"option":"2 and 3","correct":true},{"id":1670504,"option":"1, 2 and 3","correct":false}]},{"q":"<p>Your organization wants to enhance its storage capacity and backup policies. This company uses Kubernetes to manage consistency and has&nbsp;Storage Classes. Which of the following does not come under&nbsp;StorageClass?</p>\n\n<p>&nbsp;</p>","a":[{"id":1670497,"option":"provisioner","correct":false},{"id":1670498,"option":"reclaimPolicy","correct":false},{"id":1670499,"option":"arguments","correct":true},{"id":1670500,"option":"parameters","correct":false}]},{"q":"<p>You are using <em>Kubernetes</em> for managing files in the&nbsp;Kubernetes container.&nbsp;The Kubernetes \"Volume&nbsp;abstraction\" handles the files when a container crashes and sharing files between containers.</p>\n\n<p>Which of the following commands should you write to use a volume, specify the volumes to provide for the Pod and declare where to mount those volumes into containers?</p>\n\n<p><strong>Options</strong></p>\n\n<p>&nbsp;1.&nbsp;</p>\n\n<pre class=\"prettyprint\"><code>.spec.volumes\n.spec.containers[\"all\"].volumeMounts</code></pre>\n\n<p>2.&nbsp;</p>\n\n<pre class=\"prettyprint\"><code>.spec.volume\n.spec.containers[\"*\"].volumeMount</code></pre>\n\n<p>3.&nbsp;</p>\n\n<pre class=\"prettyprint\"><code>.spec.volume\n.spec.containers[].volumeMount</code></pre>\n\n<p>4.&nbsp;</p>\n\n<pre class=\"prettyprint\"><code>.spec.volumes\n.spec.containers[*].volumeMounts</code></pre>","a":[{"id":1669915,"option":"1","correct":false},{"id":1669916,"option":"2","correct":false},{"id":1669917,"option":"3","correct":false},{"id":1669918,"option":"4","correct":true}]},{"q":"<p>You are using <em>Kubernetes</em> for managing files in the&nbsp;Kubernetes container.&nbsp;The Kubernetes \"Volume&nbsp;abstraction\" handles the files when a container crashes.&nbsp;</p>\n\n<p>Kubernetes supports many types of volumes. A Pod can use any number of volume types simultaneously.&nbsp;Which of the following is&nbsp;true when a pod ceases to exist?</p>\n\n<ol>\n\t<li>Kubernetes does not destroy persistent volumes</li>\n\t<li>Kubernetes&nbsp;destroys ephemeral volumes</li>\n\t<li>Kubernetes does not destroy ephemeral volumes</li>\n\t<li>For any kind of volume in a given pod, data is preserved across container restarts.</li>\n</ol>","a":[{"id":1669911,"option":"2 and 4","correct":false},{"id":1669912,"option":"3 and 4","correct":false},{"id":1669913,"option":"1, 2 and 4","correct":true},{"id":1669914,"option":"1, 3 and 4","correct":false}]},{"q":"<p>There is a company that has a highly distributed system with a huge variety of data clouds and multiple virtual machines. The company has started using Kubernetes to manage consistency in the work.&nbsp;</p>\n\n<p>Which&nbsp;are some of the problems faced by on-disk&nbsp;for&nbsp;applications when running in containers?</p>\n\n<ol>\n\t<li>Files are lost when the container crash.</li>\n\t<li>A \"Pod\" uses any number of volume types simultaneously</li>\n\t<li>Sharing files between containers running together in a \"Pod\"</li>\n</ol>\n\n<p>&nbsp;</p>","a":[{"id":1668827,"option":"1 and 2","correct":false},{"id":1668828,"option":"2 and 3","correct":false},{"id":1668829,"option":"1 and 3","correct":true},{"id":1668830,"option":"1 , 2 and 3","correct":false}]},{"q":"<p>An&nbsp;organization is working on cloud infrastructure using <em>Kubernetes</em><strong> </strong>to reduce cost and increase&nbsp;competency.&nbsp;Every node in a Kubernetes cluster runs a<strong> </strong><em>kube-proxy</em> for implementing a form of virtual IP for Services. Which of the following data structure is used by the \"IPVS proxy mode\" as the underlying data structure which&nbsp;works in the kernel space?</p>","a":[{"id":1668263,"option":"Dynamic Arrays","correct":false},{"id":1668264,"option":"Linked List","correct":false},{"id":1668265,"option":"Hash Table","correct":true},{"id":1668266,"option":"Stack","correct":false}]},{"q":"<p>Alice is working in an&nbsp;organization, which is working with cloud infrastructure using <em>Kubernetes</em><strong> </strong>to reduce cost and work. She is taking care of networking in Kubernetes. Which of the following concern is not handled by Kubernetes Networking?</p>\n\n<p>&nbsp;</p>","a":[{"id":1668259,"option":"Containers within a Pod use networking to communicate via loopback","correct":false},{"id":1668260,"option":"The Service resource lets you expose an application running in Pods to be reachable from inside your cluster","correct":true},{"id":1668261,"option":"Cluster networking provides communication between different Pods","correct":false},{"id":1668262,"option":"You can also use Services to publish services only for consumption inside your cluster","correct":false}]},{"q":"<p>An organization is managing its cloud activities using<strong> </strong><em>Kubernetes</em>. Many of the resources like failed or completed pods, objects without owner references and unused containers need cleaning. Kubernetes has various mechanisms for<em><strong> Garbage Collection</strong></em> to clean up cluster resources.</p>\n\n<p>If&nbsp;in&nbsp;v1.20+&nbsp;the garbage collector detects an invalid cross-namespace \"ownerReference\"&nbsp; then which of the following&nbsp;warning event with a reason and an&nbsp;invalid dependent is reported?</p>","a":[{"id":1665610,"option":"OwnerInvalidNamespace and involvedObj","correct":false},{"id":1665611,"option":"InvalidNamespace and involvedObj","correct":false},{"id":1665612,"option":"OwnerReferenceInvalidNamespace and involvedObj","correct":false},{"id":1665613,"option":"OwnerRefInvalidNamespace and involvedObject","correct":true}]},{"q":"<p>There is an&nbsp;MNC that wants to adopt cloud infrastructure to manage their workload in a cost-effective and consistent way. The cloud infrastructure technologies let you run <em>Kubernetes</em> on public, private, and hybrid clouds. The Kubernetes <em>cloud controller manager</em> lets you link your cluster into your cloud provider's API.</p>\n\n<p>Which of the following&nbsp;access&nbsp;the service controller inside the cloud controller managers require on various API objects?</p>\n\n<ol>\n\t<li>Get</li>\n\t<li>Create</li>\n\t<li>Update</li>\n\t<li>Patch</li>\n\t<li>Delete</li>\n</ol>","a":[{"id":1665606,"option":"1, 2 and 3","correct":false},{"id":1665607,"option":"1, 3 and 4","correct":true},{"id":1665608,"option":"1, 2, 3 and 4","correct":false},{"id":1665609,"option":"1, 2, 3, 4 and 5","correct":false}]},{"q":"<p>A company is planning to increase its&nbsp;competence and efficiency by performing work with minimum cost by making use of methodology like Devops, so they decided to work with <em>Kubernetes </em>to get their jobs done at a low cost and&nbsp;save much time of deployment. But&nbsp;there are some things which Kubernetes is not. Which of the following are those?</p>\n\n<p><strong>Options</strong></p>\n\n<ol>\n\t<li>Kubernetes aims to support stateless and stateful workloads.</li>\n\t<li>Kubernetes provide application-level services, such as middleware, data-processing frameworks, databases, caches, and cluster storage systems as built-in services.</li>\n\t<li>Kubernetes allows you to automatically mount a storage system of your choice.</li>\n\t<li>Kubernetes restarts containers that fail, replaces containers, kills containers that don't respond to your user-defined health check, and doesn't advertise them to clients until they are ready to serve.</li>\n</ol>","a":[{"id":1664134,"option":"1","correct":false},{"id":1664135,"option":"2","correct":true},{"id":1664136,"option":"3","correct":false},{"id":1664137,"option":"4","correct":false}]},{"q":"<p>There is a company that has a highly distributed system with a huge variety of data clouds and multiple virtual machines. The company has started using Kubernetes to manage consistency in the work. You have several nodes in the Kubernetes Cluster. How can you have nodes added to API Server?</p>\n\n<ol>\n\t<li>The kubelet on a node self-registers to the control plane</li>\n\t<li>The user manually add a Node object</li>\n</ol>","a":[{"id":1664032,"option":"1","correct":false},{"id":1664033,"option":"2","correct":false},{"id":1664034,"option":"Either 1 or 2","correct":true},{"id":1664035,"option":"None of these","correct":false}]},{"q":"<p>A company is using <em>Kubernetes</em> to provide&nbsp;improved scalability and availability to its applications. Which of the following Kubernetes <em>Node Components</em>&nbsp;maintains network rules on nodes which&nbsp;allows network communication to&nbsp;Pods from network sessions inside or outside of the cluster?</p>","a":[{"id":1662645,"option":"kubelet","correct":false},{"id":1662646,"option":"etcd","correct":false},{"id":1662647,"option":"kube-proxy","correct":true},{"id":1662648,"option":"Container runtime","correct":false}]},{"q":"<p>A company wants&nbsp;IT teams to more efficiently manage large applications across many containers by handling many of the nitty-gritty details of maintaining container-based apps. As a solution, they came up with <em>Kubernetes control plane components</em>.</p>\n\n<p>Which of the following Control Plane Component allows you to combines several logically independent control loops into a single binary that you run as a single process?</p>","a":[{"id":1662641,"option":"kube-apiserver","correct":false},{"id":1662642,"option":"kube-scheduler","correct":false},{"id":1662643,"option":"kubelet","correct":false},{"id":1662644,"option":"cloud-controller-manager","correct":true}]},{"q":"<p>An organization is using the Kubernetes&nbsp;system for deploying applications and more efficiently utilizing the containerized infrastructure that powers the apps. It makes apps more resilient and performant.</p>\n\n<p>Which of the following is/are not true about Kubernetes?</p>\n\n<ol>\n\t<li>Kubernetes is&nbsp;monolithic</li>\n\t<li>Kubernetes is an all-inclusive PaaS (Platform as a Service) system</li>\n\t<li>Kubernetes does not deploy source code and does not build your application</li>\n</ol>","a":[{"id":1662010,"option":"1 and 3","correct":false},{"id":1662011,"option":"2 and 3","correct":false},{"id":1662012,"option":"1 and 2","correct":true},{"id":1662013,"option":"All of the above","correct":false}]},{"q":"<p>Earlier organizations used to run applications on physical servers.&nbsp;There was no way to define resource boundaries for applications in a physical server, and this caused resource allocation issues. As a solution to these, Virtual machines (VMs) and Containers were introduced for&nbsp;better utilization of resources in a physical server.&nbsp;</p>\n\n<p>Which of the following are correct&nbsp;differences between Virtual machines and Containers?</p>\n\n<p><strong>Differences</strong></p>\n\n<ol>\n\t<li>Virtual machines have their own Operating system whereas containers&nbsp;share the Operating system&nbsp;among the applications</li>\n\t<li>Virtual machines have their own filesystem&nbsp;whereas a Container has a shared filesystem</li>\n\t<li>Virtual machines have their own share of CPU and memory&nbsp;whereas a container has a shared memory</li>\n\t<li>Virtual machines&nbsp;size is very large whereas containers are considered lightweight</li>\n\t<li>Virtual machines use a lot of system memory whereas containers require very less memory</li>\n</ol>","a":[{"id":1661431,"option":"2, 3 and 4","correct":false},{"id":1661432,"option":"2, 3 and 5","correct":false},{"id":1661433,"option":"1 , 4 and 5","correct":true},{"id":1661434,"option":"1, 2, 3 and 5","correct":false}]},{"q":"<p>You are developing an app on Gradle. For this, you are developing a build cache and are looking for configuring remote HTTP cache. Which of the following commands is useful in helping configure remote HTTP cache?</p>\n\n<p><strong>Options</strong></p>\n\n<p><strong>1.</strong></p>\n\n<pre class=\"prettyprint\"><code>buildCache {\nremote(HttpBuildCache) {\nurl = 'https://example.com:8123/cache/'\ncredentials {\nusername = 'build-cache-user'\npassword = 'some-complicated-password'\n}\n}\n}</code></pre>\n\n<p><strong>2.</strong></p>\n\n<pre class=\"prettyprint\"><code>buildCache {\nremote(HttpBuildCache) {\nurl = 'https://example.com:8123/cache/'\nallowUntrustedServer = true\n}\n}</code></pre>\n\n<p><strong>3.</strong></p>\n\n<pre class=\"prettyprint\"><code>boolean isCiServer = System.getenv().containsKey(\"CI\")\n\nbuildCache {\nremote(HttpBuildCache) {\nurl = 'https://example.com:8123/cache/'\npush = isCiServer\n}\n}</code></pre>\n\n<p><strong>4.</strong></p>\n\n<pre class=\"prettyprint\"><code>buildCache {\nlocal {\ndirectory = new File(rootDir, 'build-cache')\nremoveUnusedEntriesAfterDays = 30\n}\n}</code></pre>\n\n<p><br>\n </p>","a":[{"id":1662869,"option":"1","correct":true},{"id":1662870,"option":"2","correct":false},{"id":1662871,"option":"3","correct":false},{"id":1662872,"option":"4","correct":false}]},{"q":"<p>You are working on Kubernetes and have processed to run a stateless application. You have created a deployment based on the YAML file. Now, you want to look at the display information about the deployment. Which of the following can be used to display the information?</p>","a":[{"id":1662857,"option":"kubectl get deployment nginx-deployment","correct":false},{"id":1662858,"option":"kubectl describe deployment nginx-deployment","correct":true},{"id":1662859,"option":"kubectl describe deployment yaml-deployment","correct":false},{"id":1662860,"option":"kubectl get deployment yaml-deployment","correct":false}]},{"q":"<p>X is developing a football score app in docker. He/she wants to see the layers that make up the image for a particular file. Which of the following docker command can be used to see the layers of the required image?</p>","a":[{"id":1662853,"option":"docker image history football","correct":true},{"id":1662854,"option":"docker image module football","correct":false},{"id":1662855,"option":"docker image layer football","correct":false},{"id":1662856,"option":"docker image notrunc football","correct":false}]},{"q":"<p>You are working on a cloud native app in docker. You wish to run it in Azure. You have logged in to your Azure account. You need to create a docker context associated with ACI to deploy apps in API. Which of the following command syntax is used in creating a new context name?</p>","a":[{"id":1662849,"option":"docker context create name","correct":false},{"id":1662850,"option":"docker context aci create name","correct":false},{"id":1662851,"option":"docker aci context create name","correct":false},{"id":1662852,"option":"docker context create aci name","correct":true}]},{"q":"<p>Labels are a mechanism for applying metadata to docker objects. You are assigned the task of labeling objects in your applications. Which of these cannot be used in key-value pairs of labels?</p>","a":[{"id":1662845,"option":"com.example.*","correct":false},{"id":1662846,"option":"com.docker.*","correct":true},{"id":1662847,"option":"com.filename.*","correct":false},{"id":1662848,"option":"com.newfile.*","correct":false}]},{"q":"<p>You are working on an application in Docker. You want to increase the controllability of contents from dockerfile. You tried creating a copy file but even then you faced some limitations in gaining control. You have decided to change the base image. You proceed by creating a new base image named hello. Which of the following ways cannot be used to create the same?</p>\n\n<p><strong>Options</strong></p>\n\n<p><strong>1.</strong></p>\n\n<pre class=\"prettyprint\"><code>FROM scratch\nADD hello /\nCMD [\"/hello\"]</code></pre>\n\n<p><strong>2.</strong></p>\n\n<pre class=\"prettyprint\"><code>container# apt-get update &amp;&amp; apt-get install build-essential\ncontainer# cd /build\ncontainer# gcc -o hello -static -nostartfiles example.c\ndocker run --rm example</code></pre>\n\n<p><strong>3.</strong></p>\n\n<pre class=\"prettyprint\"><code>$ sudo debootstrap xenial xenial &gt; /dev/null\n$ sudo tar -C xenial -c . | docker import - xenial\n$ docker run xenial cat /etc/lsb-release\nDISTRIB_ID=Ubuntu\nDISTRIB_RELEASE=16.04\nDISTRIB_CODENAME=xenial\nDISTRIB_DESCRIPTION=\"Ubuntu 16.04 LTS\"</code></pre>\n\n<p><strong>4.</strong></p>\n\n<pre class=\"prettyprint\"><code>docker build --tag hello</code></pre>\n\n<p><br>\n<br>\n </p>","a":[{"id":1662841,"option":"1","correct":false},{"id":1662842,"option":"2","correct":false},{"id":1662843,"option":"3","correct":false},{"id":1662844,"option":"4","correct":true}]},{"q":"<p>You are working on developing an app on Gradle. You are looking forward to configuring Gradle behavior with the help of the following methods.<br>\n1. System properties<br>\n2. Environment variables<br>\n3. Command-line flags<br>\n4. Gradle properties<br>\n<br>\nHow would you work with these methods in the order of priority?</p>","a":[{"id":1662837,"option":"3->1->4->2","correct":true},{"id":1662838,"option":"1->2->4->3","correct":false},{"id":1662839,"option":"3->2->1->4","correct":false},{"id":1662840,"option":"1->4->3->2","correct":false}]},{"q":"<p>You are developing an app with Gradle. You are looking forward to create multiple project guilds using a tree. Which of the following ways can you use to build the tree for the given scenario?</p>","a":[{"id":1662833,"option":"Use the node command to initiate the tree","correct":false},{"id":1662834,"option":"Use the build-tree command to build a multi project tree","correct":false},{"id":1662835,"option":"Use the tree command to create a new tree","correct":false},{"id":1662836,"option":"Use the include command to create tree for multi projects","correct":true}]},{"q":"<p>You are required to conduct a parameterised test in Junit. You have already annotated the test class with @RunWith. You have also created a public static method with @Parameters. The method returns the test dataset as an array. What should be done after creating the above said method with @parameters?</p>","a":[{"id":1662821,"option":"Creating test variables using the object variable from the public static method created previously","correct":false},{"id":1662822,"option":"Creating a public constructor that takes in one row of the test data","correct":true},{"id":1662823,"option":"Creating instance variables for all the features/columns in the test data","correct":false},{"id":1662824,"option":"Running the TestRunner Class in order to test the test data","correct":false}]},{"q":"<p>You are working with Junit for developing an app. You want to unestablish the fixture for testing an app. You have decided to close the network connection. Which of the following ways can be used for the mentioned scenario?</p>","a":[{"id":1662817,"option":"Using breakDown method to force close the network connection","correct":false},{"id":1662818,"option":"Passing the status code to closeNetwork method to destabilise the network","correct":false},{"id":1662819,"option":"Using tearDown method to close the network","correct":true},{"id":1662820,"option":"Using the closeNetwork method to interrupt the network connection","correct":false}]},{"q":"<p>You are developing an app with Junit. You want to check whether two object reference points point to the same object. Which of the following ways can be used for the above scenario?</p>\n\n<p><strong>Options</strong></p>\n\n<p><strong>1.</strong></p>\n\n<p>Passing both the objects to assertSameObject method to check for reference errors</p>\n\n<p><strong>2.</strong></p>\n\n<p>Passing one of the objects to assertSame so as to view the other objects with the same reference points</p>\n\n<p><strong>3.</strong></p>\n\n<p>Passing both the objects to the method assertNotSameObject to check for references</p>\n\n<p><strong>4.</strong></p>\n\n<p>Passing both the objects to the method assertSame method to determine the reference points</p>","a":[{"id":1662813,"option":"1","correct":false},{"id":1662814,"option":"2","correct":false},{"id":1662815,"option":"3","correct":false},{"id":1662816,"option":"4","correct":true}]},{"q":"<p>For a Jenkins server, X, Y and Z are three interdependent projects. You want to find what Z builds are being used by X. How can you do this?</p>","a":[{"id":1662797,"option":"Configure X and Y to record fingerprint of X.jar","correct":false},{"id":1662798,"option":"Configure X and Y to record fingerprint of Y.jar","correct":false},{"id":1662799,"option":"Configure X and Z to record fingerprint of X.jar","correct":true},{"id":1662800,"option":"Configure X and Z to record fingerprint of Z.jar","correct":false}]},{"q":"<p>While working on a Jenkins server, your job is on queue and the reason indicated is \"Agents are offline\". How can you resolve this case of executor starvation?</p>","a":[{"id":1662793,"option":"Use labels without tying builds to specific agents.","correct":true},{"id":1662794,"option":"Use labels to run any build on any machine.","correct":false},{"id":1662795,"option":"Use labels that are assigned to specific agents.","correct":false},{"id":1662796,"option":"Use labels that are independent of controllers.","correct":false}]},{"q":"<p>You are utilizing the plugin feature of the Bolt orchestration tool. The plugin is written to retrieve a certain list from an inventory. How can you input the authentication credentials to complete the task?</p>\n\n<p><strong>Options</strong></p>\n\n<p><strong>1.</strong></p>\n\n<p>By defining the path to retrieve parameters from an external taskfile that can be then stored as static data.</p>\n\n<p><strong>2.</strong></p>\n\n<p>By assigning the plugin hook to the desired plugin and giving a task name in the command line to invoke the match parameters.</p>\n\n<p><strong>3.</strong></p>\n\n<p>By prevalidating parameters in the task metadata file and testing and matching parameters during usage.</p>\n\n<p><strong>4.</strong></p>\n\n<p>By defining parameters in the task metadata file and then specifying parameters during usage.</p>","a":[{"id":1662761,"option":"1","correct":false},{"id":1662762,"option":"2","correct":false},{"id":1662763,"option":"3","correct":false},{"id":1662764,"option":"4","correct":true}]},{"q":"<p>You are authoring a module that is compatible with the most recently released version dependency. Which of the following must you avoid while specifying the version to ensure compatibility?</p>\n\n<p><strong>Options</strong></p>\n\n<p><strong>1.</strong></p>\n\n<p>Specify the multiple compatible minor and major versions, explicitly.</p>\n\n<p><strong>2.</strong></p>\n\n<p>Specify only the multiple compatible major versions, explicitly.</p>\n\n<p><strong>3.</strong></p>\n\n<p>Exclude the next unreleased major version from the upper bound.</p>\n\n<p><strong>4.</strong></p>\n\n<p>Include the next unreleased major version from the upper bound.</p>","a":[{"id":1662757,"option":"1","correct":false},{"id":1662758,"option":"2","correct":false},{"id":1662759,"option":"3","correct":true},{"id":1662760,"option":"4","correct":false}]},{"q":"<p>You are forwarding inbound traffic to backends in an application developed with Kubernetes using proxying. You decide to switch to other methods. You then configured DNS records to have multiple A values and applied round-robin name resolution. What is the issue associated with this particular approach?</p>","a":[{"id":1662741,"option":"DNS implementations give high priority to record TTLs and hence, round robin cannot be used.","correct":false},{"id":1662742,"option":"Some apps cache the data multiple times and could interrupt round robin name resolution.","correct":false},{"id":1662743,"option":"DNS records could impose a high load on DNS.","correct":true},{"id":1662744,"option":"There is no issue. Both round robin and proxying can be used.","correct":false}]},{"q":"<p>You are looking forward to assign memory resources to containers and pods. You have created a namespace as example_pod and also a pod as example_pod. You have also verified if the container is running or not. Which of the following ways can be used to view detailed information about example_pod?</p>\n\n<p><strong>Options</strong></p>\n\n<p><strong>1.</strong></p>\n\n<p>Passing the namespace and output to kubectl get pod, along with the pod</p>\n\n<p><strong>2.</strong></p>\n\n<p>Passing the namespace and output to kubectl describe, along with the pod</p>\n\n<p><strong>3.</strong></p>\n\n<p>Creating a container using the given resources and using the info command</p>\n\n<p><strong>4.</strong></p>\n\n<p>Using info-pod command to view detailed information</p>","a":[{"id":1662725,"option":"1","correct":true},{"id":1662726,"option":"2","correct":false},{"id":1662727,"option":"3","correct":false},{"id":1662728,"option":"4","correct":false}]},{"q":"<p>You are creating a cluster in Kubernetes. You use 1000 nodes under the cluster and each cluster has 150 nodes. But for some reasons, you could not create the cluster, successfully. What could be the potential reason for an unsuccessful result in such a case?</p>","a":[{"id":1662721,"option":"One cannot have more than 500 nodes in a cluster.","correct":false},{"id":1662722,"option":"Pods contains nodes and not vice versa.","correct":false},{"id":1662723,"option":"There should be no more than 1000 containers in total.","correct":false},{"id":1662724,"option":"One cannot have more than 110 pods in a node.","correct":true}]},{"q":"<p>You are working on Kubernetes and are trying to use kubectl exec command. You are required to replace some long options with short ones to have a concise code. Which of the following options will help in writing concise codes?</p>","a":[{"id":1662713,"option":"Using --si in the place of --stdin","correct":false},{"id":1662714,"option":"Using --i instead of the longer option --stdin","correct":true},{"id":1662715,"option":"Using --y instead of --tty","correct":false},{"id":1662716,"option":"Using --so instead of the longer option -stdout","correct":false}]},{"q":"<p>You are working on deploying an app in Kubernetes. You are required to provide service inside a cluster without any external access. Which of the following services is useful in the mentioned scenario?</p>","a":[{"id":1662709,"option":"Using Cluster IP service inside the clusters","correct":true},{"id":1662710,"option":"Making use of NodePort service within clusters","correct":false},{"id":1662711,"option":"Using LoadBalancer service between the clusters","correct":false},{"id":1662712,"option":"Using Internal service inside the clusters","correct":false}]},{"q":"<p>As a Docker developer, one has to switch between the developing environment and the production environment. You have used bind mounts on the developing side and stored the data by volume on the production side. You have also isolated Docker processes from host processes. What should you be doing on the production side, apart from the ones mentioned above, in order to ensure smooth processing?</p>\n\n<p><strong>Options</strong></p>\n\n<p><strong>1.</strong></p>\n\n<p>Running an NTP client on Docker host and in each container before syncing them all to the NTP server.</p>\n\n<p><strong>2.</strong></p>\n\n<p>Using secrets to store sensitive application data and configs for non-sensitive information.</p>\n\n<p><strong>3.</strong></p>\n\n<p>Using CI/CD pipeline to automatically build and test the environment.</p>\n\n<p><strong>4.</strong></p>\n\n<p>Using multi-stage build to enhance the versatility and robustness of the environment.</p>","a":[{"id":1662705,"option":"1","correct":true},{"id":1662706,"option":"2","correct":false},{"id":1662707,"option":"3","correct":false},{"id":1662708,"option":"4","correct":false}]},{"q":"<p>You are working on a storage driver API to model a key/value storage. There are several storage drivers as potential options. Which of the following would help you to resolve this?</p>\n\n<p><strong>Options</strong></p>\n\n<p><strong>1.</strong></p>\n\n<p>Use StorageDriverFactory interface to select a driver through parameter mapping</p>\n\n<p><strong>2.</strong></p>\n\n<p>Use factory, New to select correct instances for the driver</p>\n\n<p><strong>3.</strong></p>\n\n<p>Use selectSuite function to select the correct driver required through internal processing</p>\n\n<p><strong>4.</strong></p>\n\n<p>Use immemory and filesystem driver as they are generalized drivers that contain all other drivers in them.</p>","a":[{"id":1662701,"option":"1","correct":true},{"id":1662702,"option":"2","correct":false},{"id":1662703,"option":"3","correct":false},{"id":1662704,"option":"4","correct":false}]},{"q":"<p>Rebuilding images is great to ensure their security. You have chosen an image that is sufficiently small. You have also installed a package to increase the security of the chosen image. You have tagged the image and rebuilt it. While executing you find that the image did not get rebuilt successfully, which of the following options is likely the cause for the same?</p>","a":[{"id":1662697,"option":"Choosing larger images reduces rebuilding errors","correct":false},{"id":1662698,"option":"Unnecessary packages cause errors while rebuilding images","correct":true},{"id":1662699,"option":"Tagging is not a mandatory step and has to be done to the base image only","correct":false},{"id":1662700,"option":"Some data has to be stored in the container before rebuilding","correct":false}]},{"q":"<p>You are working on an app in Docker. You are determined to optimize Docker with CI/CD deployment. You have created an access token for DockerHub as the prerequisite step. Which of the following would be the first step in reducing build time and hence optimizing CI/CD operation?</p>","a":[{"id":1662693,"option":"Using Docker Hub Password","correct":false},{"id":1662694,"option":"Using build caches to reuse the layers","correct":true},{"id":1662695,"option":"Making the release images to go to Dockerhub exclusively","correct":false},{"id":1662696,"option":"Setting up functions to push PR images","correct":false}]},{"q":"<p>You are working on a delivery app on Docker. You are assigned the task of converting an application defined in compose file to AWS resource. Which of the following keys can be used with EC2 support for the same?</p>\n\n<p><strong>Options</strong></p>\n\n<p><strong>1.</strong></p>\n\n<pre class=\"prettyprint\"><code>Using service.deploy.update_config to select machine type</code></pre>\n\n<p><strong>2.</strong></p>\n\n<pre class=\"prettyprint\"><code>Using service.deploy.resources to select machine type and AMI</code></pre>\n\n<p><strong>3.</strong></p>\n\n<pre class=\"prettyprint\"><code>Using service.deploy.placement to select machine type and AMI</code></pre>\n\n<p><strong>4.</strong></p>\n\n<pre class=\"prettyprint\"><code>Using service.deploy.labels to select the labels regarding AMI</code></pre>\n\n<p> </p>","a":[{"id":1662689,"option":"1","correct":false},{"id":1662690,"option":"2","correct":false},{"id":1662691,"option":"3","correct":true},{"id":1662692,"option":"4","correct":false}]},{"q":"<p>B has just started developing apps using Docker. He/she has learned to persist the data but wants to provide additional data into the containers. Which of the following ways would help B to achieve this?</p>","a":[{"id":1662685,"option":"Using Mountpoints to mount source code","correct":false},{"id":1662686,"option":"Using Bindmounts to control the mountpoints","correct":true},{"id":1662687,"option":"Accessing Nodemount to control code variations","correct":false},{"id":1662688,"option":"Making use of Mountroot","correct":false}]},{"q":"<p>You are required to build multi-container applications. You need to select your CLI. Which among these would give you a better performance?</p>","a":[{"id":1662681,"option":"Using main docker CLI since it offers more versatility","correct":false},{"id":1662682,"option":"Using Daemon CLI as it gives persistent container management","correct":false},{"id":1662683,"option":"Using Compose CLI as it offers more functionality","correct":true},{"id":1662684,"option":"Using either Daemon CLI or Compose CLI","correct":false}]},{"q":"<p>You are working on an app on Docker. You have to create an environment variable to change the behavior of a process. Which of the flags can be used to set an environment variable from an external file?</p>\n\n<p><strong>Options</strong></p>\n\n<p><strong>1.</strong></p>\n\n<pre class=\"prettyprint\"><code>Using the key --e alongside docker run command</code></pre>\n\n<p><strong>2.</strong></p>\n\n<pre class=\"prettyprint\"><code>Using the key--env alongside docker var command</code></pre>\n\n<p><strong>3.</strong></p>\n\n<pre class=\"prettyprint\"><code>Using the key --env-file alongside docker run command</code></pre>\n\n<p><strong>4.</strong></p>\n\n<pre class=\"prettyprint\"><code>Using the key --env-ext alongside docker var command</code></pre>\n\n<p> </p>","a":[{"id":1662677,"option":"1","correct":false},{"id":1662678,"option":"2","correct":false},{"id":1662679,"option":"3","correct":true},{"id":1662680,"option":"4","correct":false}]},{"q":"<p>You are working on a new application in Docker using docker hub API. You need to create an authentication token. The screen showed a response code of 200. In which of the following scenarios will this response code be displayed?</p>","a":[{"id":1662673,"option":"When the authentication fails","correct":false},{"id":1662674,"option":"When the authentication is successful","correct":true},{"id":1662675,"option":"When there is a server error","correct":false},{"id":1662676,"option":"When the session has timed out","correct":false}]},{"q":"<p>You are working on an app in Kubernetes. You are defining a service and posting it to the API server to create a new instance. By mistake, you have created the service without any selectors. Which of the following steps should be done to rectify any erroneous situation that would arise because of this?</p>\n\n<p><strong>Options</strong></p>\n\n<p><strong>1.</strong></p>\n\n<pre class=\"prettyprint\"><code>Create multi ports:\nkind: Serviceports\nmetadata:\nname: my-service\nspec:\nports:\n- name: http\nprotocol: TCP\nport: 80\ntargetPort: 9376\n- name: https\nprotocol: TCP\nport: 443\ntargetPort: 9377</code></pre>\n\n<p><strong>2.</strong></p>\n\n<pre class=\"prettyprint\"><code>Add endpoints manually:\napiVersion: v1\nkind: Endpoints\nmetadata:\nname: my-service\nsubsets:\n- addresses:\n- ip: 192.0.2.42\nports:\n- port: 9376</code></pre>\n\n<p><strong>3.</strong></p>\n\n<pre class=\"prettyprint\"><code>Add environment variables with the help of redis master: \nREDIS_MASTER_SERVICE_HOST=10.0.0.11\nREDIS_MASTER_SERVICE_PORT=6379\nREDIS_MASTER_PORT=tcp://10.0.0.11:6379\nREDIS_MASTER_PORT_6379_TCP=tcp://10.0.0.11:6379\nREDIS_MASTER_PORT_6379_TCP_PROTO=tcp\nREDIS_MASTER_PORT_6379_TCP_PORT=6379\nREDIS_MASTER_PORT_6379_TCP_ADDR=10.0.0.11</code></pre>\n\n<p><strong>4.</strong></p>\n\n<p>There would be no error as the missing error would be defaulted by the system.</p>","a":[{"id":1662865,"option":"1","correct":false},{"id":1662866,"option":"2","correct":true},{"id":1662867,"option":"3","correct":false},{"id":1662868,"option":"4","correct":false}]},{"q":"<p>You are working on an app in Kubernetes. You are working with Kubectl. You have created many services. You wish to see the name of the replication controller. Which of the following commands is used to view the replication controller name?</p>","a":[{"id":1662861,"option":"Kubectl get rc","correct":false},{"id":1662862,"option":"Kubectl get rcname","correct":false},{"id":1662863,"option":"Kubectl describe rcname","correct":false},{"id":1662864,"option":"Kubectl describe rc","correct":true}]},{"q":"<p>While using Maven, X builds an integration-test lifecycle phase and clears the test. When Y, a co-worker attempts to build an integration test; Y fails. Which of the following could be a probable cause?</p>","a":[{"id":1662829,"option":"X has specified appserver paths in a profile, that is specified in the settings.xml.","correct":true},{"id":1662830,"option":"Y has specified appserver paths in a profile, that is specified in the settings.xml.","correct":false},{"id":1662831,"option":"X has generated two profiles with different value properties for the same integration.","correct":false},{"id":1662832,"option":"Y has generated two profiles with different value properties for the same integration.","correct":false}]},{"q":"<p>While working with Maven, you want to include a snippet of the source code into your project. What must you do to include the snippet?</p>","a":[{"id":1662825,"option":"Assign a unique path to the snippet.","correct":false},{"id":1662826,"option":"Assign a unique ID to the snippet.","correct":true},{"id":1662827,"option":"Assign snippet to an archetype.","correct":false},{"id":1662828,"option":"Assign snippet to a module.","correct":false}]},{"q":"<p>You have developed an app using Junit. You want to test the app by running the test cases. So you use runClasses method. Which of the following options is the necessary step for the same?</p>","a":[{"id":1662809,"option":"Importing Failure after accessing runClasses","correct":false},{"id":1662810,"option":"Importing JUnitCore for accessing runClasses","correct":true},{"id":1662811,"option":"Importing runClasses from the TestCase class","correct":false},{"id":1662812,"option":"Importing Result from runClasses","correct":false}]},{"q":"<p>You are working with Junit for developing an app. You are in the middle of coding and want to test only certain portions of the code.Which of the following ways is used to disable the unfinished codes while running?</p>","a":[{"id":1662805,"option":"Annotating the unfinished code with @disable will disable them while running","correct":false},{"id":1662806,"option":"Using @Test code to eliminate unwanted codes while running.","correct":false},{"id":1662807,"option":"Annotating with @ignore to disable unfinished codes","correct":true},{"id":1662808,"option":"Using @ignoreTest to disable unfinished codes","correct":false}]},{"q":"<p>You are setting up a Pipeline project for a local repository on GitHub. While carrying out the SSH protocol, you realise that the SSH key has not been registered with your Git server.How do you proceed?</p>\n\n<p><strong>Options</strong></p>\n\n<p><strong>1.</strong></p>\n\n<p>Use the automatically generated Blue Ocean SSH key pair to link with the Git remote server and then configure the key.</p>\n\n<p><strong>2.</strong></p>\n\n<p>In the Connect to GitHub section, enter your GitHub access token and SSH token into the Your GitHub access token field for configuration.</p>\n\n<p><strong>3.</strong></p>\n\n<p>Scan the local repository’s branches for a SSH protocol and commence a Pipeline run for each branch to configure.</p>\n\n<p><strong>4.</strong></p>\n\n<p>Configure the SSH public key component of this key pair for the remote Git server’s user account and return to the BO interface.</p>","a":[{"id":1662801,"option":"1","correct":false},{"id":1662802,"option":"2","correct":false},{"id":1662803,"option":"3","correct":false},{"id":1662804,"option":"4","correct":true}]},{"q":"<p>You are working with a Pipeline project whose source code has not been cloned from a repository. How will you define the Pipeline?</p>","a":[{"id":1662789,"option":"Through Blue Ocean","correct":false},{"id":1662790,"option":"Through the SCM","correct":false},{"id":1662791,"option":"Through the classic UI","correct":true},{"id":1662792,"option":"Through Snippet Generator","correct":false}]},{"q":"<p>X is setting up credentials in a Jenkins system. The credentials are to be added from a Pipeline project. What will X choose under the scope field?</p>","a":[{"id":1662785,"option":"System","correct":false},{"id":1662786,"option":"Global","correct":true},{"id":1662787,"option":"Host","correct":false},{"id":1662788,"option":"Server","correct":false}]},{"q":"<p>You want to create a set of alerts in Nagios Log Server. The servers fulfill the following needs:</p>\n\n<pre class=\"prettyprint\"><code>Server 1: Data is to be intermittently checked for abnormalities.\nServer 2: In a critical event, to constantly check for abnormalities.\nServer 3: For previously configured hosts, data is no longer being received.</code></pre>\n\n<p>Identify the three servers being used in this case.</p>\n\n<p><strong>Options</strong></p>\n\n<p><strong>1.</strong></p>\n\n<pre class=\"prettyprint\"><code>Server 1: Query \nServer 2: Real Time\nServer 3: Host Freshness</code></pre>\n\n<p><strong>2.</strong></p>\n\n<pre class=\"prettyprint\"><code>Server 1: Real Time\nServer 2: Host Freshness\nServer 3: Query</code></pre>\n\n<p><strong>3.</strong></p>\n\n<pre class=\"prettyprint\"><code>Server 1: Host Freshness\nServer 2: Query\nServer 3: Real Time</code></pre>\n\n<p><strong>4.</strong></p>\n\n<pre class=\"prettyprint\"><code>Server 1: Real Time\nServer 2: Query\nServer 3: Host Freshness</code></pre>\n\n<p><br>\n </p>","a":[{"id":1662781,"option":"1","correct":true},{"id":1662782,"option":"2","correct":false},{"id":1662783,"option":"3","correct":false},{"id":1662784,"option":"4","correct":false}]},{"q":"<p>You want to implement a Secure Sockets Layer to encrypt connections to the Nagios Fusion server. What must you do to set up the SSL?</p>","a":[{"id":1662777,"option":"Generate a certificate signature through any Certificate Authority.","correct":false},{"id":1662778,"option":"Generate a challenge password through any Certificate Authority.","correct":false},{"id":1662779,"option":"Generate a private key file through any Certificate Authority.","correct":false},{"id":1662780,"option":"Generate a certificate through any Certified Authority.","correct":true}]},{"q":"<p>The backup of Nagios you created was version 5.0.0. You want to restore this backup on the system where Nagios crashed. What version of Nagios should you install in the target system?</p>\n\n<p><strong>Options</strong></p>\n\n<p><strong>1.</strong></p>\n\n<p>5.0.0</p>\n\n<p><strong>2.</strong></p>\n\n<p>5.1.0</p>\n\n<p><strong>3.</strong></p>\n\n<p>4.9.9</p>\n\n<p><strong>4.</strong></p>\n\n<p>4.0.0</p>","a":[{"id":1662773,"option":"1","correct":true},{"id":1662774,"option":"2","correct":false},{"id":1662775,"option":"3","correct":false},{"id":1662776,"option":"4","correct":false}]},{"q":"<p>You are an administrator that has deployed a dashboard for streamlining a project using Nagios. If you need to enable users to edit the dashboard, which of the following would you require to do?</p>","a":[{"id":1662769,"option":"Utilise the dashboard","correct":false},{"id":1662770,"option":"Share the dashboard","correct":false},{"id":1662771,"option":"Unsync the dashboard","correct":true},{"id":1662772,"option":"Sync the dashboard","correct":false}]},{"q":"<p>You are creating a passive host to monitor log inputs on the Nagios Log Server. What is the first step that you must take in this case?</p>","a":[{"id":1662765,"option":"Enable REST API Access On Nagios XI User.","correct":false},{"id":1662766,"option":"Test that correct events are being received.","correct":true},{"id":1662767,"option":"Download a custom script to be used in creation.","correct":false},{"id":1662768,"option":"Enable and configure NXLog CE.","correct":false}]},{"q":"<p>While working on a project, you are setting up a Puppet Development Kit behind a proxy on a Windows system. What must you do to ensure PDK communication?</p>","a":[{"id":1662753,"option":"Include necessary modules to the PDK profile.","correct":false},{"id":1662754,"option":"Assign appropriate environment variables.","correct":true},{"id":1662755,"option":"Anonymise command arguments.","correct":false},{"id":1662756,"option":"Resource the PDK profile on an open terminal.","correct":false}]},{"q":"<p>During the disaster recovery process, you encounter an error after provisioning the backup replica. Which of the following is the best possible solution for this?</p>","a":[{"id":1662749,"option":"Reinitialise replica","correct":true},{"id":1662750,"option":"Reinstall primary server","correct":false},{"id":1662751,"option":"Enable new replica","correct":false},{"id":1662752,"option":"Enable new primary server","correct":false}]},{"q":"<p>You have set the benchmark compliance for nodes on Puppet Comply. How do you access the assigned profile of a node?</p>","a":[{"id":1662745,"option":"Use the Custom profile menu","correct":false},{"id":1662746,"option":"Use the Node dropdown menu","correct":false},{"id":1662747,"option":"Click on the Set Profiles option","correct":false},{"id":1662748,"option":"Click on the Node option","correct":true}]},{"q":"<p>You are looking to configuring a pod to use a PersistentVolume for storage. You have created a persistent volume for the nodes in the cluster. You, then proceed to create a pod for storing. The output showed an error. Identify the potential reason.</p>","a":[{"id":1662737,"option":"Persistent volume requires the presence of a pre existing pod.","correct":false},{"id":1662738,"option":"Persistent Volume storage can be used in a cluster with only one node.","correct":true},{"id":1662739,"option":"The storage has to be initiated for each and every node.","correct":false},{"id":1662740,"option":"hostPath has to be initiated before creating pod.","correct":false}]},{"q":"<p>X is working on Kubernetes. X is required to specify a CPU request for a container. X is looking to configure the file by establishing a CPU limit. Which of the following should you use to specify the same?</p>\n\n<p><strong>Options</strong></p>\n\n<p><strong>1.</strong></p>\n\n<p>Using args command to provide the limit as an argument to the container</p>\n\n<p><strong>2.</strong></p>\n\n<p>Specifying memory: limits in the container's resource manifest</p>\n\n<p><strong>3.</strong></p>\n\n<p>Requesting memory limit by using resources:requests</p>\n\n<p><strong>4.</strong></p>\n\n<p>Including resources:limits in the container's resource manifest</p>","a":[{"id":1662733,"option":"1","correct":false},{"id":1662734,"option":"2","correct":false},{"id":1662735,"option":"3","correct":false},{"id":1662736,"option":"4","correct":true}]},{"q":"<p>You are creating an object in Kubernetes for the application you are developing. You want to modify the objects before creating them. Which of the following ways can you use to modify?</p>","a":[{"id":1662729,"option":"Using a combination of set and create command","correct":true},{"id":1662730,"option":"Using patch command for directly modifying contents","correct":false},{"id":1662731,"option":"Creating new labels to modify the content","correct":false},{"id":1662732,"option":"Creating and using logs to modify the content, accordingly","correct":false}]},{"q":"<p>You are working with Kubernetes on an application. You need to create a task that runs repeatedly as per a specific schedule. Which of the following resources can be used to recur a task?</p>","a":[{"id":1662717,"option":"Using Job for recurring tasks","correct":false},{"id":1662718,"option":"Making use of DaemonSet to schedule runs","correct":false},{"id":1662719,"option":"Setting up Cronjobs to recur a task","correct":true},{"id":1662720,"option":"Setting up Deployment for recurring tasks","correct":false}]},{"q":"<p>If Alice is required to integrate the Continuous Integration workflow in her software development process, then which of the following sequences of steps should she follow in order to complete this action:</p>\n\n<ol>\n\t<li>The Continuous Integration server detects that changes have occurred in the version control repository, so the Continuous Integration server retrieves the latest copy of the code from the repository and then executes a build script, which integrates the software.</li>\n\t<li>The developer commits the code to the version control repository. Meanwhile, the Continuous Integration server on the integration build machine polls source code repository for changes.</li>\n\t<li>The Continuous Integration server generates feedback of the build results to the specified project members.</li>\n\t<li>The Continuous Integration server continues to poll for changes in the version control repository and the whole process repeats.</li>\n\t<li>Unit tests are then carried out if the build of that project passes. If the tests are successful, the code is ready to be deployed to either the staging or production server.</li>\n</ol>\n\n<p> </p>","a":[{"id":573206,"option":"2 -> 3 -> 4 -> 1 -> 5","correct":false},{"id":573207,"option":"3 -> 2 -> 1 -> 5 -> 4","correct":false},{"id":573208,"option":"3 -> 1 -> 5 -> 2 -> 4","correct":false},{"id":573209,"option":"2 -> 1 -> 3 -> 5 -> 4","correct":true}]},{"q":"<p>In Azure DevOps, you are configuring your Continuous Delivery (CD) pipeline for your Jenkins Continuous Integration (CI) Server. If you are required. If  you are required to integrate your Jenkins Server with the Azure Pipelines, then which of the following actions can be performed in this scenario:</p>\n\n<ol>\n\t<li>Run CI jobs in the Jenkins server separately.</li>\n\t<li>Include a docker file in your CD pipeline to avoid Azure pipeline concurrency.</li>\n\t<li>Wrap a Jenkins CI job inside the Azure pipeline</li>\n</ol>","a":[{"id":1161879,"option":"1 and 2","correct":false},{"id":1161880,"option":"2 and 3","correct":false},{"id":1161881,"option":"1 and 3","correct":true},{"id":1161882,"option":"All of these","correct":false}]},{"q":"<p>In Azure DevOps, you want to implement configuration management by using the Ansible tool.</p>\n\n<p>Which of the following agents contain the build dependencies that are used to perform tests on your web applications?</p>","a":[{"id":1161887,"option":"Build ","correct":true},{"id":1161888,"option":"Deployment ","correct":false},{"id":1161889,"option":"Repository ","correct":false},{"id":1161890,"option":"Executable ","correct":false}]},{"q":"<p>In Azure DevOps, if you are required to implement a continuous orchestration process by using the Kubernetes container-orchestration system, then which of the following orchestration services is used to upgrade your Kubernetes cluster?</p>","a":[{"id":1161875,"option":"Azure Container Registry (ACR)","correct":false},{"id":1161876,"option":"Azure Kubernetes Services (AKS)","correct":true},{"id":1161877,"option":"Azure Kubernetes Orchestrator (AKO)","correct":false},{"id":1161878,"option":"None of these","correct":false}]},{"q":"<p>In Azure DevOps, which of the following statements about Azure Pipelines are correct:</p>\n\n<ol>\n\t<li>It is a fully-integrated continuous integration service and a partially-integrated continuous delivery service.</li>\n\t<li>It can be deployed to major cloud services including Azure services.</li>\n\t<li>It is used to configure and automate the build, delivery tools, and environment in the YAML language.</li>\n</ol>","a":[{"id":1161907,"option":"1 and 2","correct":false},{"id":1161908,"option":"2 and 3","correct":true},{"id":1161909,"option":"1 and 3","correct":false},{"id":1161910,"option":"All of these","correct":false}]},{"q":"<p>In Azure DevOps, you are working on the docker container.</p>\n\n<p>Which of the following properties will be enabled if you combine Azure DevOps and Azure integrations with the docker container:</p>\n\n<ol>\n\t<li>You can build custom docker images by using an Azure DevOps hosted Linux agent.</li>\n\t<li>You can push and store the docker images in a private repository.</li>\n\t<li>You can deploy and run the images inside the container.</li>\n</ol>","a":[{"id":1161895,"option":"1 and 2","correct":false},{"id":1161896,"option":"2 and 3","correct":false},{"id":1161897,"option":"1 and 3","correct":false},{"id":1161898,"option":"All of these","correct":true}]},{"q":"<p>In TFS, you are working with Azure Repos. If you are working with the Git distributed version control, then which of the following statements about the isolation of the code with the forks are correct:</p>\n\n<ol>\n\t<li>A fork is a complete copy of a repository, including all files, commits.</li>\n\t<li>The new fork acts as if someone cloned the original repository and then pushed it to a new, empty repository.</li>\n\t<li>After a fork has been created, new files, folders, and branches are not shared between the repositories unless a pull request carries these files along.</li>\n</ol>","a":[{"id":1156891,"option":"1 and 2","correct":false},{"id":1156892,"option":"2 and 3","correct":false},{"id":1156893,"option":"1 and 3","correct":false},{"id":1156894,"option":"All of these","correct":true}]},{"q":"<p>In TFS, you are managing the process templates. If you are required to upload a process template, then which of the following conditions must be valid:</p>\n\n<ol>\n\t<li>Process template names must be unique and must contain less than or equal to 256 Unicode characters.</li>\n\t<li>Process template folders must contain at least one executable (.exe) files in them.</li>\n\t<li>The total size of the process template must less than or equal to 2GB.</li>\n</ol>\n\n<p> </p>","a":[{"id":1156923,"option":"1 and 2","correct":false},{"id":1156924,"option":"2 and 3","correct":false},{"id":1156925,"option":"1 and 3","correct":true},{"id":1156926,"option":"All of these","correct":false}]},{"q":"<p>In Azure DevOps Server, you are working on the Azure test plans. Which of the following manual tests are performed by the development teams, including developers, testers, UX teams, product owners by exploring the software systems without using test plans or test suites?</p>","a":[{"id":1156903,"option":"Planned manual testing","correct":false},{"id":1156904,"option":"User Acceptance testing","correct":false},{"id":1156905,"option":"Exploratory testing","correct":true},{"id":1156906,"option":"Stakeholder feedback","correct":false}]},{"q":"<p>In Azure DevOps Server, which of the following statements about the Azure Pipelines are correct:</p>\n\n<ol>\n\t<li>It is a cloud service that you can use to automatically build and test your code project and make it available to other users.</li>\n\t<li>It is used to connect the Azure repositories with the SQL Server instance to make all the duplicate elements are removed from the data resources.</li>\n\t<li>It combines continuous integration (CI) and continuous delivery (CD) to test and build the user's code consistently.</li>\n</ol>\n\n<p> </p>","a":[{"id":1156899,"option":"1 and 2","correct":false},{"id":1156900,"option":"2 and 3","correct":false},{"id":1156901,"option":"1 and 3","correct":true},{"id":1156902,"option":"All of these","correct":false}]},{"q":"In Azure DevOps, which of the following statements about the advantages of using Team Foundation Version Control are correct:<br>&nbsp;&nbsp;&nbsp;&nbsp;1. It is used to automate the testing and the code analysis of a project.<br>&nbsp;&nbsp;&nbsp;&nbsp;2. It is used to remove cache files automatically from the project.<br>&nbsp;&nbsp;&nbsp;&nbsp;3. It is used to create a workflow for the project.","a":[{"id":1161923,"option":"1 and 2","correct":false},{"id":1161924,"option":"2 and 3","correct":false},{"id":1161925,"option":"1 and 3","correct":true},{"id":1161926,"option":"All of these","correct":false}]},{"q":"Which of the following statements about Azure DevOps Repos are correct:<br>&nbsp;&nbsp;&nbsp;&nbsp;1. They are a set of repositories that allow users to version control and manage the project code.<br>&nbsp;&nbsp;&nbsp;&nbsp;2. They are used to monitor code, solutions, builds, commits, pushes, pull requests, and branching information about projects.<br>&nbsp;&nbsp;&nbsp;&nbsp;3. They cannot control solutions to the project by using their repos links.","a":[{"id":1161915,"option":"1 and 2","correct":true},{"id":1161916,"option":"2 and 3","correct":false},{"id":1161917,"option":"1 and 3","correct":false},{"id":1161918,"option":"All of these","correct":false}]},{"q":"In Azure DevOps, which of the following statements about Azure Boards are correct?","a":[{"id":1161919,"option":"It provides a set of properties such as native support for Scrum and Kanban, customizable dashboards, and integrated reporting.","correct":true},{"id":1161920,"option":"It provides various CI/CD pipeline services for all public repositories.","correct":false},{"id":1161921,"option":"It provides image content for Docker containers.","correct":false},{"id":1161922,"option":"All of these","correct":false}]},{"q":"In Azure DevOps, which of the following properties is used to provide a workspace for planning tests, execution, and analysis of your team project?","a":[{"id":1161903,"option":"Test Suite","correct":false},{"id":1161904,"option":"Test Hub","correct":true},{"id":1161905,"option":"Test Plan","correct":false},{"id":1161906,"option":"Test Center","correct":false}]},{"q":"In Azure DevOps, you are working on continuous testing using Selenium. You have created a unit testing folder to perform UI tests. If you are required to include your Internet Explorer browser driver to execute the tests, then which of the following packages must be included in the NuGet Package Manager workspace?","a":[{"id":1161883,"option":"Selenium.IEDriver.WebDriver","correct":false},{"id":1161884,"option":"Selenium.IE.WebDriver","correct":false},{"id":1161885,"option":"Selenium.WebDriver.IEDriver","correct":true},{"id":1161886,"option":"Selenium.WebDriver.IE","correct":false}]},{"q":"In Azure DevOps, you are implementing configuration management by using the Puppet tool. If you are required to deploy your application with the Puppet tool in Azure, then which of the following sequence of steps are correct:<br>&nbsp;&nbsp;&nbsp;&nbsp;1. Run the Puppet configuration on a node.<br>&nbsp;&nbsp;&nbsp;&nbsp;2. Provision a Puppet master and a node in Azure<br>&nbsp;&nbsp;&nbsp;&nbsp;3. Install a Puppet agent on the node<br>&nbsp;&nbsp;&nbsp;&nbsp;4. Configure the Puppet production environment<br>&nbsp;&nbsp;&nbsp;&nbsp;5. Test the production environment configuration system<br>&nbsp;&nbsp;&nbsp;&nbsp;6. Create a Puppet program","a":[{"id":1161891,"option":"1 -> 2 -> 3 -> 4 -> 5 -> 6","correct":false},{"id":1161892,"option":"2 -> 3 -> 4 -> 5 -> 6 -> 1","correct":true},{"id":1161893,"option":"3 -> 4 -> 5 -> 6 -> 1 -> 2","correct":false},{"id":1161894,"option":"4 -> 5 -> 6 -> 1 -> 2 -> 3","correct":false}]},{"q":"In TFS, which of the following authorization tokens is used to authenticate Azure DevOps?","a":[{"id":1156915,"option":"OAuth","correct":false},{"id":1156916,"option":"Basic Authorization","correct":false},{"id":1156917,"option":"Personal Access Token (PAT)","correct":true},{"id":1156918,"option":"Alternate Password","correct":false}]},{"q":"In TFS, which of the following workflow models is followed by Team Foundation Version Control?","a":[{"id":1156883,"option":"Server","correct":false},{"id":1156884,"option":"Local ","correct":false},{"id":1156885,"option":"Both of these","correct":true},{"id":1156886,"option":"None of these","correct":false}]},{"q":"Which of the following are the advantages of using Team Foundation Server?","a":[{"id":1156875,"option":"It provides a set of collaboration tools that work with your existing IDEs or editors.","correct":false},{"id":1156876,"option":"It provides support to AGILE methodologies.","correct":false},{"id":1156877,"option":"It provides support for multiple languages and IDEs.","correct":false},{"id":1156878,"option":"All of these","correct":true}]},{"q":"<p>Which of the following features of Docker makes it faster and lightweight when compared to other virtualization techniques?</p>","a":[{"id":655336,"option":"Container runs on physical hardware via an inter-mediation layer","correct":false},{"id":655337,"option":"Container runs the userspace on top of the operating system’s kernel","correct":true},{"id":655338,"option":"Container consists of applications, guest operating systems, and necessary binaries and libraries","correct":false},{"id":655339,"option":"All of these","correct":false}]},{"q":"<p>Which of the following statements represent the advantages of using Continuous Integration (CI) and Continuous Deployment (CD):</p>\n\n<ol>\n\t<li>Reduces overhead across the development and deployment process.</li>\n\t<li>Reduces the time and effort for integrations of different code changes</li>\n\t<li>Enables a quick feedback mechanism on every change</li>\n</ol>","a":[{"id":656697,"option":"1 and 2","correct":false},{"id":656698,"option":"2 and 3","correct":false},{"id":656699,"option":"1 and 3","correct":true},{"id":656700,"option":"All of these","correct":false}]},{"q":"<p>In Azure DevOps, you are working on Azure Pipelines. If you are required to run pipeline tests, then which of the following outcomes in this scenario are correct:</p>\n\n<ol>\n\t<li>Successful</li>\n\t<li>Passed</li>\n\t<li>Aborted</li>\n\t<li>Not impacted</li>\n</ol>","a":[{"id":1161911,"option":"1, 2, and 3","correct":false},{"id":1161912,"option":"2, 3, and 4","correct":true},{"id":1161913,"option":"1, 2, and 4","correct":false},{"id":1161914,"option":"1, 3, and 4","correct":false}]},{"q":"<p>In TFS, which of the following the building blocks of the work item tracking system as well as other sub-systems you access through Azure Boards or an on-premises Azure DevOps Server?</p>","a":[{"id":1156895,"option":"TFVC","correct":false},{"id":1156896,"option":"Process template","correct":true},{"id":1156897,"option":"Access key","correct":false},{"id":1156898,"option":"None of these","correct":false}]},{"q":"<p>In TFS, if you are required to customize the process template, then which of the following tools support in performing this action:</p>\n\n<ol>\n\t<li>XML editor</li>\n\t<li>TFS Team Project Manager tool</li>\n\t<li>Process Editor tool</li>\n</ol>","a":[{"id":1156867,"option":"1 and 2","correct":false},{"id":1156868,"option":"2 and 3","correct":false},{"id":1156869,"option":"1 and 3","correct":false},{"id":1156870,"option":"All of these","correct":true}]},{"q":"In TFS, which of the following components of Azure DevOps Server is a storage space for repositories that provide unlimited cloud-hosted private Git repositories?","a":[{"id":1156911,"option":"Azure Repos","correct":true},{"id":1156912,"option":"Azure Pipelines","correct":false},{"id":1156913,"option":"Azure Artifacts","correct":false},{"id":1156914,"option":"Azure Test Plans","correct":false}]},{"q":"In TFS, which of the following version control systems is a centralized version control system?","a":[{"id":1156887,"option":"Git","correct":false},{"id":1156888,"option":"TFVC","correct":true},{"id":1156889,"option":"Both of these","correct":false},{"id":1156890,"option":"None of these","correct":false}]},{"q":"In TFS, which of the following components of Azure DevOps Server enables you to create, host, and also share packages among your team?","a":[{"id":1156907,"option":"Azure Boards","correct":false},{"id":1156908,"option":"Azure Repos","correct":false},{"id":1156909,"option":"Azure Test Plans","correct":false},{"id":1156910,"option":"None of these","correct":true}]},{"q":"<p>Which of these is the appropriate term for the following statement:</p>\n\n<p>It is a software engineering practice in which teams develop, build, test, and release software in short cycles.</p>","a":[{"id":656869,"option":"Continuous integration","correct":false},{"id":656870,"option":"Continuous delivery","correct":true},{"id":656871,"option":"Continuous deployment","correct":false},{"id":656872,"option":"None of these","correct":false}]},{"q":"<p>In Azure DevOps, you are running tests on Azure Pipelines for a test runner. If you are required to slice a test suite, then which of the following YAML variables can be used to indicate the total number of slices that are available in the test run?</p>","a":[{"id":1161927,"option":"System.JobPositionInPhase","correct":false},{"id":1161928,"option":"System.TotalJobsInPhase","correct":true},{"id":1161929,"option":"System.TotalSlicesInPhase","correct":false},{"id":1161930,"option":"None of these","correct":false}]},{"q":"<p>In Azure DevOps, you are required to implement continuous monitoring by using the Nagios monitoring tool. </p>\n\n<p>Which of the following commands is used to enable Apache and Nagios services after installing the Nagios’ core and plugins?</p>","a":[{"id":1161931,"option":"chkconfig httpd on && chkconfig nagios on","correct":true},{"id":1161932,"option":"install chkconfig -m httpd on && chkconfig nagios on","correct":false},{"id":1161933,"option":"install chkconfig -a httpd enable-nagios on","correct":false},{"id":1161934,"option":"install chkconfig -t httpd on && chkconfig enable-nagios","correct":false}]},{"q":"<p>Which of these is the right approach to publish a report as a Jenkins artifact based on the following Jenkins setup:</p>\n\n<pre class=\"prettyprint\"><code>stage('Build the code')\nnode('master'){\n# Some commands to follow\n}\nstage(\"Run the tests and Generate Report\")\nnode('slave'){\n# Some commands to follow\n}\n</code></pre>\n\n<p> </p>","a":[{"id":532070,"option":"        stage('Build the code')\r\n        node('master'){\r\n                # Some commands to follow\r\n        }\r\n        stage(\"Run the tests and Generate Report\")\r\n        node('slave'){\r\n                # Some commands to follow\r\n                stash ReportFile\r\n        }\r\n        node('master'){\r\n                unstash ReportFile\r\n                archiveArtefacts ReportFile\r\n        }","correct":true},{"id":532071,"option":"        stage('Build the code')\r\n        node('master'){\r\n                # Some commands to follow\r\n        }\r\n        stage(\"Run the tests and Generate Report\")\r\n        node('slave'){\r\n                # Some commands to follow\r\n                archiveArtefacts ReportFile\r\n        }\r\n        ","correct":false},{"id":532072,"option":"        stage('Build the code')\r\n        node('master'){\r\n                # Some commands to follow\r\n        }\r\n        stage(\"Run the tests and Generate Report\")\r\n        node('slave'){\r\n                # Some commands to follow\r\n        }\r\n        archiveArtefacts ReportFile","correct":false},{"id":532073,"option":"        stage('Build the code')\r\n        node('master'){\r\n                # Some commands to follow\r\n        }\r\n        stage(\"Run the tests and Generate Report\")\r\n        node('slave'){\r\n                # Some commands to follow\r\n                stash ReportFile\r\n                archiveArtefacts ReportFile\r\n        }\r\n","correct":false}]},{"q":"<p>Which of the following Docker CLI commands is used to find Docker image layers and its size? </p>","a":[{"id":655816,"option":"docker history  \"Image_Id\"","correct":true},{"id":655817,"option":"docker layers  \"Image_Id\"","correct":false},{"id":655818,"option":"docker image -layers  \"Image_Id\"","correct":false},{"id":655819,"option":"docker image layers  \"Image_Id\"","correct":false}]},{"q":"<p>You are working with CI/CD pipelines. You are creating a Continuous Integration (CI) commit pipeline using Docker. If you are required to download the source code from the repository, then which of the following levels of this commit pipeline is implemented to perform this action in this scenario?</p>","a":[{"id":658108,"option":"Checkin level","correct":false},{"id":658109,"option":"Checkout level","correct":true},{"id":658110,"option":"Compile level","correct":false},{"id":658111,"option":"Unit test level","correct":false}]},{"q":"<p>In Azure DevOps, which of the following statements represents the advantages of using Azure Artifacts:</p>\n\n<ol>\n\t<li>Maven, npm, and NuGet Package feeds can be created and shared from public and private sources.</li>\n\t<li>A fully integrated management can be added to CI/CD pipelines with a single click.</li>\n\t<li>Docker images from the Jenkins server can be imported into the public repositories.</li>\n</ol>","a":[{"id":1161899,"option":"1 and 2","correct":true},{"id":1161900,"option":"2 and 3","correct":false},{"id":1161901,"option":"1 and 3","correct":false},{"id":1161902,"option":"All of these","correct":false}]},{"q":"Which of the following statements are functions of the Team Foundation Version Control?","a":[{"id":1156879,"option":"Checking files in and out","correct":false},{"id":1156880,"option":"Deciding who can access the version control data","correct":false},{"id":1156881,"option":"Branching and merging tasks with different versions of the source code","correct":true},{"id":1156882,"option":"All of these","correct":false}]},{"q":"<p>In Jenkins, which of the following is not available as a part of the ENV variable set by default?<br>\n </p>","a":[{"id":532074,"option":"JOB_NAME\r\n","correct":false},{"id":532075,"option":"BUILD_NUMBER","correct":false},{"id":532076,"option":"USER_ID","correct":true},{"id":532077,"option":"WORKSPACE","correct":false}]},{"q":"<p>In Docker, which of the following execution result sequences is correct?</p>","a":[{"id":655851,"option":"Docker Image -> Dockerfile -> Docker Container","correct":false},{"id":655852,"option":"Docker Image  -> Docker Container -> Dockerfile","correct":false},{"id":655853,"option":"Dockerfile -> Docker Container -> Docker Image   ","correct":false},{"id":655854,"option":"Dockerfile -> Docker Image -> Docker Container","correct":true}]},{"q":"Work item types and Test Client OMs are a part of TFS Software Development Kits. Which of the following sets of APIs contains these components?","a":[{"id":1156871,"option":"SOAP","correct":true},{"id":1156872,"option":"RESTful","correct":false},{"id":1156873,"option":"Both of these","correct":false},{"id":1156874,"option":"None of these","correct":false}]},{"q":"<p>You want to set up a new project in Jenkins for a unique requirement that involves running your build for all the branches in your SCM.<br>\nWhich of the following will you choose from the drop down to set this up?</p>","a":[{"id":532078,"option":"Multi-branch pipeline","correct":true},{"id":532079,"option":"Freestyle","correct":false},{"id":532080,"option":"Pipeline","correct":false},{"id":532081,"option":"Folder","correct":false}]}]