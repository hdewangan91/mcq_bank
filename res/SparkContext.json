[{"q":"<p>In Spark Streaming, the following new <strong>StreamingContext</strong> object is created from an existing <strong>SparkContext</strong> object and a context is defined. Which of the following statements about this scenario are correct:</p>\n\n<p><strong>Object</strong></p>\n\n<pre class=\"prettyprint\"><code>import org.apache.spark.streaming._\nval sc = ...                \nval ssc = new StreamingContext(sc, Seconds(5))</code></pre>\n\n<p><strong>Statements</strong> </p>\n\n<ol>\n\t<li>Once a Context is started, new streaming computations cannot be set up or added</li>\n\t<li>stop() on Context can only stop the SparkContext</li>\n\t<li>Multiple StreamingContext can be active in a JVM at the same time</li>\n\t<li>Once a Context is stopped, it cannot be restarted</li>\n</ol>","a":[{"id":1166905,"option":"1 and 2","correct":false},{"id":1166906,"option":"2 and 3","correct":false},{"id":1166907,"option":"3 and 4","correct":false},{"id":1166908,"option":"1 and 4","correct":true}]},{"q":"<p>You are required to set the following options if you want both batch and streaming queries for a Kafka source. Which statements about this scenario are correct:</p>\n\n<p><strong>Options</strong></p>\n\n<ol>\n\t<li>assign</li>\n\t<li>subscribePattern</li>\n\t<li>subscribe</li>\n\t<li>kafka.bootstrap.servers</li>\n</ol>\n\n<p><strong>Statements</strong></p>\n\n<ol>\n\t<li><strong>assign</strong>:<strong> </strong>Represents the specific TopicPartitions to consume</li>\n\t<li><strong>subscribePattern</strong>: Represents the topic list to subscribe</li>\n\t<li><strong>subscribe</strong>:<strong> </strong>Represents the list of subscribers </li>\n\t<li><strong>kafka.bootstrap.servers</strong>:<strong> </strong>Represents the pattern used to subscribe to topics</li>\n\t<li>All these options—assign, subscribe, and subscribePattern—can be specified for a Kafka source</li>\n\t<li>Only one of these options—assign, subscribe, or subscribePattern—can be specified for a Kafka source</li>\n</ol>","a":[{"id":1167987,"option":"1, 2, 4","correct":false},{"id":1167988,"option":"1, 4, 6","correct":true},{"id":1167989,"option":"3, 5, 6","correct":false},{"id":1167990,"option":"1, 3, 4, 6","correct":false}]},{"q":"<p>In Spark Streaming integrated with Kafka, which of these statements about the following code are correct:</p>\n\n<p><strong>Code</strong></p>\n\n<pre class=\"prettyprint\"><code>def function(): StreamingContext = {\n  val hack_ssc = new StreamingContext(...)   \n  val h_lines = hack_ssc.socketTextStream(...) \n  ...\n  hack_ssc.checkpoint(checkpointDirectory)   \n  hack_ssc\n}\nval hack_context = StreamingContext.getOrCreate(checkpointDirectory, function _)\nhack_context. ...\nhack_context.start()\nhack_context.awaitTermination()</code></pre>\n\n<p><strong>Statements </strong></p>\n\n<ol>\n\t<li>If the program starts for the first time, the <strong>StreamingContext.getOrCreate()</strong> function allows you to create a new StreamingContext class, set up all the streams, and then call <strong>stop()</strong>.</li>\n\t<li>If the program restarts after failure, then the <strong>StreamingContext.getOrCreate()</strong> function allows you to replace a StreamingContext from the checkpoint data in the checkpoint directory.</li>\n\t<li>If the checkpointDirectory exists, then the context is replaced from the checkpoint data.</li>\n\t<li>If the checkpoint directory does not exist, that is, running for the first time, then the <strong>functionToCreateContext </strong>function is called to create a new context and disable the DStreams.</li>\n</ol>","a":[{"id":1167886,"option":"1, 2, 3","correct":false},{"id":1167887,"option":"2, 3, 4","correct":false},{"id":1167888,"option":"1, 3, 4","correct":false},{"id":1167889,"option":"None of these","correct":true}]},{"q":"<p>In Spark Streaming, the following new <strong>StreamingContext</strong> object is created from an existing <strong>SparkContext</strong> object. Which of these steps can be performed after a context is defined:</p>\n\n<p><strong>Object</strong></p>\n\n<pre class=\"prettyprint\"><code>import org.apache.spark.streaming._\nval sc = ...                \nval ssc = new StreamingContext(sc, Seconds(5))</code></pre>\n\n<p><strong>Steps </strong></p>\n\n<ol>\n\t<li>Defining the input sources by creating an input DStream</li>\n\t<li>Start receiving the data and then process it using streamingContext.start()</li>\n</ol>","a":[{"id":1166901,"option":"1","correct":false},{"id":1166902,"option":"2","correct":false},{"id":1166903,"option":"All of these","correct":true},{"id":1166904,"option":"None of these","correct":false}]},{"q":"<p>In Spark Streaming integrated with Kafka, which of these statements describe the task performed by the following code:</p>\n\n<pre class=\"prettyprint\"><code>createStream(StreamingContext ssc, String zkQuorum, String groupId, scala.collection.immutable.Map&lt;String,Object&gt; topics, StorageLevel storageLevel)</code></pre>\n\n<p><strong>Statements</strong></p>\n\n<ol>\n\t<li><strong>createStream</strong> allows you to provide the input stream details, which include the systems where the port is created and the topic name.</li>\n\t<li>ssc represents the StreamingFile object.</li>\n\t<li>groupId represents the customer ID of this particular customer.</li>\n\t<li>Checkpoint operations are performed on a stream of data after it is received.</li>\n</ol>","a":[{"id":1167974,"option":"1 and 2","correct":false},{"id":1167975,"option":"2 and 3","correct":false},{"id":1167976,"option":"1 and 3","correct":true},{"id":1167977,"option":"All of these","correct":false}]}]